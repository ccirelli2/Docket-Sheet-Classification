{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# THE PURPOSE OF THIS STAGE IS TO OBTAIN THE WORD FREQUENCY FOR OUR TOP 5 WORDS THAT WILL BE FED INTO\n",
    "# THE STAGE 4 PREDICTIVE ALGORITHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IMPORT PACKAGES & PERSONAL MODULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir(r'/home/ccirelli2/Desktop/Docket-Sheet-Classification/Modules')\n",
    "import Step3_Module_Ngrams_Docketsheet_KeyWord_FreqDist as stp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import Docket sheets w/ pre-classified time periods\n",
    "os.chdir(r'/home/ccirelli2/Desktop/Docket-Sheet-Classification/Data_Files_applicable_all_code')\n",
    "docketsheet_master_file = pd.read_excel(r'DocketSheet Classification_70_02.22.2018.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Directory where files are lo\n",
    "os.chdir(r'/home/ccirelli2/Desktop/Docket-Sheet-Classification/Result_Ngrams')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "List_files = [file for file in os.listdir() if 'TopWords' in file]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_KeyWordAppearance_DocketsheetEntries(Docketsheet, File, \n",
    "                                             Write2Excel = 'False', Destination_location = None):\n",
    "    '''\n",
    "    Purpose     = The purpose of this code is to generate a dataframe whose rows are the docketsheet entries, columns\n",
    "                  the key ngrams and the values the appearance of these ngrams in each docketsheet entry. \n",
    "    Input       = 1.) A dataframe representing the docketsheet limited to only those applicable rows and columns. \n",
    "                  2.) A file containing the list of key words for a particular calculation + methodology\n",
    "                      combination.  \n",
    "    Operations  = 1.) Create a dataframe to house the rows and columns \n",
    "                  2.) Since the names of each docketsheet entry do not indicate their position in the dataframe, create\n",
    "                      and object to keep the count of the num of rows that we iterate over, which will later be used in\n",
    "                      the naming of the rows in the new dataframe returned to the user. \n",
    "                  3.) Create a list to capture the values 0/1 that will represent the appearance or not of each of the\n",
    "                      Ngrams.  This list is the row of values for each docketsheet entry. \n",
    "                  4.) Clean and tokenize the text in the same manner as was done in Stage1. \n",
    "                  5.) Create Ngrams of the docketsheet rows in the same manner as was done in Stage1. \n",
    "                  6.) Iterate over each Ngram in the List of Ngrams input into this function. \n",
    "                  7.) Determine if the Ngram is present and add values to the List_word_matches defined earlier .\n",
    "                  8.) Define our row. \n",
    "                  9.) Append the row to our dataframe. \n",
    "    \n",
    "    '''\n",
    "       \n",
    "    # Format Docketsheet (rows / columns)\n",
    "    Docketsheet_formated = stp3.format_docket_sheet_file(Docketsheet)\n",
    "    \n",
    "    # Get Key Words From File\n",
    "    Set_key_words = stp3.get_set_KeyWords_from_file(File)\n",
    "    \n",
    "    df_file = pd.read_excel(File)\n",
    "    \n",
    "    \n",
    "    # Create New Dataframe\n",
    "    df_DAT = pd.DataFrame({}, index = Set_key_words)\n",
    "    \n",
    "    # Count of Rows\n",
    "    Count = 0\n",
    "    \n",
    "    # Iterate over row of the docketsheet df as an enumerated tuple. \n",
    "    for row in Docketsheet_formated.itertuples():\n",
    "        \n",
    "        # Star the Count of the rows\n",
    "        Count += 1\n",
    "        \n",
    "        # List to capture each row.  List will reset on each iteration of the code. \n",
    "        List_word_matches_single_row = []\n",
    "        \n",
    "        # Clean row[4], which is the text column of the docketsheet. \n",
    "        clean_tokenize_row = stp3.clean_andTokenize_text(row[4])                \n",
    "            \n",
    "        # Once the text of the row is tokenized, we need to create the Ngrams\n",
    "        docketsheet_ngrams = stp3.get_docketsheet_ngrams(clean_tokenize_row, File)\n",
    "        \n",
    "        # So iterate every word in key_word_list for each rows \n",
    "        #for Ngram in Set_key_words:\n",
    "\n",
    "        #print(('cover', 'sheet', 'pleas', 'visit') in docketsheet_ngrams)\n",
    "        \n",
    "        print(df.iloc[0])\n",
    "        \n",
    "#         for col in df_file:\n",
    "#             for Ngram in df_file[col]:\n",
    "#                 if isinstance(Ngram, str):\n",
    "                    \n",
    "#                     # Check to see if the word is in the clean text\n",
    "#                     if Ngram in list(docketsheet_ngrams):\n",
    "                                                \n",
    "#                     # If there is a match, append 1 to the list\n",
    "#                         List_word_matches_single_row.append(1)\n",
    "#                     else: \n",
    "#                         # If not, append 0\n",
    "#                         List_word_matches_single_row.append(0)\n",
    "        \n",
    "        # Create a string from the counter to add to your column name. \n",
    "        Row_num = 'row' + str(Count) + ' ' \n",
    "        \n",
    "        # Create a column in your new datafrmae to capture the case number and list of matches. \n",
    "        df_DAT[Row_num + row[1] + ' ' + str(row[2])] = List_word_matches_single_row        \n",
    "\n",
    "    # Write to Excel\n",
    "    if Write2Excel == True:\n",
    "        print('Writing dataframe to Excel')\n",
    "        os.chdir(Destination_location)\n",
    "        File_name = 'DocketSheet_WordMatches' + '_' + File\n",
    "        print('File name => ' + File_name, '\\n')\n",
    "        stp3.write_to_excel(df_DAT, Destination_location, File_name)\n",
    "        print('Your file has been saved to:  ', Destination_location)\n",
    "    \n",
    "    # Otherwise, return the dataframe to the user.    \n",
    "    else:\n",
    "        return df_DAT\n",
    "    \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import a single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TopWords_Quadgrams_CalculationI_homebrew_STDV_Top15_highest_STDV.xlsx'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "File_n =  'TopWords_Quadgrams_CalculationI_homebrew_STDV_Top15_highest_STDV.xlsx'\n",
    "File_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a function that when past a File of key words, it returns a list of unique key words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage1: STDV             ('accord', 'frap', 'usca', 'mandat')\n",
      "Stage2: STDV      ('obtain', 'pretrial', 'instruct', 'enter')\n",
      "Stage3: STDV     ('dismiss', 'motion', 'summari', 'judgment')\n",
      "Stage4: STDV          ('clerk', 'entri', 'dismiss', 'approv')\n",
      "Stage5: STDV             ('accord', 'frap', 'usca', 'mandat')\n",
      "Stage6: STDV     ('exhibit', 'exhibit', 'exhibit', 'exhibit')\n",
      "Stage7: STDV        ('final', 'report', 'recommend', 'order')\n",
      "Stage8: STDV         ('entri', 'dismiss', 'approv', 'stipul')\n",
      "Stage9: STDV             ('motion', 'extens', 'time', 'file')\n",
      "Stage10: STDV       ('adjust', 'accordingli', 'sign', 'judg')\n",
      "Stage11: STDV            ('accord', 'frap', 'usca', 'mandat')\n",
      "Name: 0, dtype: object\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values does not match length of index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-154-dc68143c37df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m get_KeyWordAppearance_DocketsheetEntries(docketsheet_master_file, \n\u001b[0;32m----> 2\u001b[0;31m                                          File_n)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-152-3718d41c893b>\u001b[0m in \u001b[0;36mget_KeyWordAppearance_DocketsheetEntries\u001b[0;34m(Docketsheet, File, Write2Excel, Destination_location)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;31m# Create a column in your new datafrmae to capture the case number and list of matches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mdf_DAT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mRow_num\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mList_word_matches_single_row\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;31m# Write to Excel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2329\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2330\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2331\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2396\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2397\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2398\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, key, value, broadcast)\u001b[0m\n\u001b[1;32m   2566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2567\u001b[0m             \u001b[0;31m# turn me into an ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2568\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sanitize_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2569\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2570\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_sanitize_index\u001b[0;34m(data, index, copy)\u001b[0m\n\u001b[1;32m   2877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2878\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2879\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Length of values does not match length of '\u001b[0m \u001b[0;34m'index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2881\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPeriodIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values does not match length of index"
     ]
    }
   ],
   "source": [
    "get_KeyWordAppearance_DocketsheetEntries(docketsheet_master_file, \n",
    "                                         File_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to Obtain a Dictionary with the list of key words for each approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict_key_words(Target_dir, delimiter = 'TopWords', Num_files = 'One', Single_file = None):\n",
    "    \n",
    "    # Change directory to your target dir\n",
    "    os.chdir(Target_dir)\n",
    "    # Define the list of files you want to obtain using the delimiter. \n",
    "    Key_word_files = [x for x in os.listdir() if delimiter in x]\n",
    "    \n",
    "    # Create a Dictionary to capture key words by file. \n",
    "    \n",
    "    Dict = {}\n",
    "    \n",
    "    for file in Key_word_files:\n",
    "        # Read the file in as a Dataframe\n",
    "        df_file = pd.read_excel(file)\n",
    "        # Create a list to capture the key words\n",
    "        List_key_words = []\n",
    "        # Iterate each column\n",
    "        for col in df_file.columns:\n",
    "            # Append to the list each word\n",
    "            for ngram in df_file[col]:\n",
    "                # Ensure its not a none value\n",
    "                if isinstance(ngram,str):\n",
    "                    # Append each word to the List of key words. \n",
    "                    List_key_words.append(ngram)\n",
    "        # Create a key for each file and values for the ngrams of each file. \n",
    "        Dict[file] = set(List_key_words)\n",
    "    \n",
    "    return Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dict_key_words = get_dict_key_words(Target_Dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"('abacu', 'corpor')\",\n",
       " \"('accordingli', 'sign')\",\n",
       " \"('adjust', 'accordingli')\",\n",
       " \"('admiss', 'buttrick')\",\n",
       " \"('admiss', 'neighbour')\",\n",
       " \"('affect', 'order')\",\n",
       " \"('affidavit', 'support')\",\n",
       " \"('also', 'extend')\",\n",
       " \"('amend', 'initi')\",\n",
       " \"('amend', 'notic')\",\n",
       " \"('answer', 'amend')\",\n",
       " \"('answer', 'complaint')\",\n",
       " \"('appeal', 'circuit')\",\n",
       " \"('appeal', 'file')\",\n",
       " \"('applic', 'receipt')\",\n",
       " \"('approv', 'settlement')\",\n",
       " \"('atla', 'courtroom')\",\n",
       " \"('attach', 'statement')\",\n",
       " \"('bahhur', 'attach')\",\n",
       " \"('batten', 'enter')\",\n",
       " \"('brearley', 'enter')\",\n",
       " \"('brown', 'univers')\",\n",
       " \"('buckholt', 'citi')\",\n",
       " \"('buckholt', 'enter')\",\n",
       " \"('buttrick', 'vice')\",\n",
       " \"('caduceu', 'occup')\",\n",
       " \"('cambridg', 'mercantil')\",\n",
       " \"('capilouto', 'enter')\",\n",
       " \"('certif', 'servic')\",\n",
       " \"('circuit', 'number')\",\n",
       " \"('complaint', 'brief')\",\n",
       " \"('complaint', 'deni')\",\n",
       " \"('complet', 'discoveri')\",\n",
       " \"('correct', 'owen')\",\n",
       " \"('counti', 'school')\",\n",
       " \"('court', 'court')\",\n",
       " \"('court', 'direct')\",\n",
       " \"('court', 'enter')\",\n",
       " \"('court', 'local')\",\n",
       " \"('court', 'report')\",\n",
       " \"('court', 'sign')\",\n",
       " \"('courtroom', 'magistr')\",\n",
       " \"('deadlin', 'affect')\",\n",
       " \"('defend', 'answer')\",\n",
       " \"('defend', 'defend')\",\n",
       " \"('defend', 'plaintiff')\",\n",
       " \"('defend', 'submit')\",\n",
       " \"('demand', 'file')\",\n",
       " \"('disclosur', 'statement')\",\n",
       " \"('discoveri', 'discoveri')\",\n",
       " \"('discoveri', 'end')\",\n",
       " \"('discoveri', 'plan')\",\n",
       " \"('dismiss', 'clerk')\",\n",
       " \"('dismiss', 'failur')\",\n",
       " \"('dismiss', 'partial')\",\n",
       " \"('exhibit', 'exhibit')\",\n",
       " \"('extend', 'period')\",\n",
       " \"('fact', 'exhibit')\",\n",
       " \"('failur', 'state')\",\n",
       " \"('file', 'answer')\",\n",
       " \"('file', 'buckholt')\",\n",
       " \"('file', 'citi')\",\n",
       " \"('file', 'coot')\",\n",
       " \"('file', 'devereux')\",\n",
       " \"('file', 'drewri')\",\n",
       " \"('file', 'geithner')\",\n",
       " \"('file', 'hawk')\",\n",
       " \"('file', 'industri')\",\n",
       " \"('file', 'ippolito')\",\n",
       " \"('file', 'kennington')\",\n",
       " \"('file', 'notic')\",\n",
       " \"('file', 'order')\",\n",
       " \"('file', 'printpack')\",\n",
       " \"('file', 'rashaan')\",\n",
       " \"('file', 'seal')\",\n",
       " \"('file', 'stone')\",\n",
       " \"('file', 'summari')\",\n",
       " \"('file', 'unboundari')\",\n",
       " \"('final', 'report')\",\n",
       " \"('form', 'enter')\",\n",
       " \"('forma', 'pauperi')\",\n",
       " \"('grant', 'applic')\",\n",
       " \"('grant', 'parti')\",\n",
       " \"('gwinnett', 'counti')\",\n",
       " \"('herebi', 'order')\",\n",
       " \"('initi', 'disclosur')\",\n",
       " \"('instruct', 'modifi')\",\n",
       " \"('joint', 'preliminari')\",\n",
       " \"('judg', 'scofield')\",\n",
       " \"('judg', 'vineyard')\",\n",
       " \"('judgment', 'repli')\",\n",
       " \"('kennington', 'attach')\",\n",
       " \"('kennington', 'metro')\",\n",
       " \"('lackland', 'modifi')\",\n",
       " \"('later', 'date')\",\n",
       " \"('law', 'order')\",\n",
       " \"('leav', 'amend')\",\n",
       " \"('long', 'brearley')\",\n",
       " \"('marx', 'enter')\",\n",
       " \"('materi', 'fact')\",\n",
       " \"('matter', 'stay')\",\n",
       " \"('medicin', 'dawkin')\",\n",
       " \"('moncrief', 'attach')\",\n",
       " \"('motion', 'approv')\",\n",
       " \"('motion', 'dismiss')\",\n",
       " \"('motion', 'grant')\",\n",
       " \"('motion', 'rule')\",\n",
       " \"('motion', 'settlement')\",\n",
       " \"('neighbour', 'vice')\",\n",
       " \"('northsid', 'rashaan')\",\n",
       " \"('notic', 'appeal')\",\n",
       " \"('number', 'enter')\",\n",
       " \"('object', 'report')\",\n",
       " \"('occup', 'medicin')\",\n",
       " \"('order', 'deadlin')\",\n",
       " \"('order', 'deposit')\",\n",
       " \"('order', 'design')\",\n",
       " \"('order', 'detail')\",\n",
       " \"('order', 'direct')\",\n",
       " \"('order', 'discoveri')\",\n",
       " \"('order', 'discuss')\",\n",
       " \"('order', 'dismiss')\",\n",
       " \"('order', 'district')\",\n",
       " \"('order', 'docket')\",\n",
       " \"('order', 'dyke')\",\n",
       " \"('order', 'enter')\",\n",
       " \"('order', 'failur')\",\n",
       " \"('order', 'head')\",\n",
       " \"('order', 'joint')\",\n",
       " \"('order', 'motion')\",\n",
       " \"('order', 'schedul')\",\n",
       " \"('order', 'shall')\",\n",
       " \"('part', 'plaintiff')\",\n",
       " \"('pend', 'motion')\",\n",
       " \"('plaintiff', 'exhibit')\",\n",
       " \"('preliminari', 'report')\",\n",
       " \"('protect', 'order')\",\n",
       " \"('receipt', 'number')\",\n",
       " \"('recommend', 'motion')\",\n",
       " \"('reflect', 'document')\",\n",
       " \"('report', 'discoveri')\",\n",
       " \"('report', 'recommend')\",\n",
       " \"('review', 'approv')\",\n",
       " \"('rule', 'pend')\",\n",
       " \"('school', 'district')\",\n",
       " \"('septemb', 'motion')\",\n",
       " \"('servic', 'discoveri')\",\n",
       " \"('settlement', 'agreement')\",\n",
       " \"('settlement', 'approv')\",\n",
       " \"('shall', 'adjust')\",\n",
       " \"('shall', 'file')\",\n",
       " \"('sharif', 'file')\",\n",
       " \"('sharif', 'fitzpatrick')\",\n",
       " \"('statement', 'materi')\",\n",
       " \"('stay', 'plaintiff')\",\n",
       " \"('stilley', 'attach')\",\n",
       " \"('strike', 'motion')\",\n",
       " \"('submiss', 'applic')\",\n",
       " \"('univers', 'attach')\",\n",
       " \"('univers', 'buckley')\",\n",
       " \"('univers', 'melnick')\",\n",
       " \"('vice', 'applic')\",\n",
       " \"('waterproof', 'enter')\",\n",
       " \"('yarbro', 'dekalb')\"}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dict_key_words['TopWords_Bigrams_CalculationIII_Correlation_Coefficient_Top15_highest_COCOEF.xlsx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_docketsheet_ngrams(Tokenized_text, List_key_words):\n",
    "    '''\n",
    "    Input      = 1.) Tokenized Text, 2.) List of key words.\n",
    "    Operations = 1.) Create an object to \n",
    "    '''\n",
    "    # Define the object Ngrams_text as an empty string\n",
    "    Ngrams_text = ''\n",
    "    # Check the length of the first key word in our Dict\n",
    "    if len(List_key_words[0]) == 1:\n",
    "    # Use our get_Ngrams function to create the Ngrams.\n",
    "        Ngrams_text = get_Ngrams(clean_tokenize_row, 'Nograms')\n",
    "    elif len(List_key_words[0]) == 2:\n",
    "        Ngrams_text = get_Ngrams(clean_tokenize_row, 'Bigrams')\n",
    "    elif len(List_key_words[0]) == 3:\n",
    "        Ngrams_text = get_Ngrams(clean_tokenize_row, 'Trigrams')\n",
    "    elif len(List_key_words[0]) == 4:\n",
    "        Ngrams_text = get_Ngrams(clean_tokenize_row, 'Quadgrams')\n",
    "    # Return to the user the Ngram_text\n",
    "    return Ngrams_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MASTER CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_funct(Docketsheet, DictKeyWords):\n",
    "\n",
    "    df = ''\n",
    "    \n",
    "    for key in DictKeyWords:\n",
    "        if 'TopWords_Quadgrams_CalculationII_AVG_not_zero_Top5_highest_STDV_AVG_below_20prct' in key:\n",
    "            Ngram_iterable = list(DictKeyWords[key])\n",
    "            df = stp3.get_KeyWordAppearance_DocketsheetEntries(Docketsheet, Ngram_iterable)\n",
    "    return df\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-5aeb51ca8733>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_funct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_docketsheet_master_file_preClass_timePeriods\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict_key_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-2bdcf4f1c5fc>\u001b[0m in \u001b[0;36mtest_funct\u001b[0;34m(Docketsheet, DictKeyWords)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'TopWords_Quadgrams_CalculationII_AVG_not_zero_Top5_highest_STDV_AVG_below_20prct'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mNgram_iterable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDictKeyWords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstp3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_KeyWordAppearance_DocketsheetEntries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDocketsheet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNgram_iterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Docket-Sheet-Classification/Modules/Step3_Module_Ngrams_Docketsheet_KeyWord_FreqDist.py\u001b[0m in \u001b[0;36mget_KeyWordAppearance_DocketsheetEntries\u001b[0;34m(Docketsheet, List_DictKeyWords)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;31m# Clean row[4], which is the text column of the docketsheet.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mclean_tokenize_row\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_andTokenize_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;31m# Once the text of the row is tokenized, we need to create the Ngrams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Docket-Sheet-Classification/Modules/Step3_Module_Ngrams_Docketsheet_KeyWord_FreqDist.py\u001b[0m in \u001b[0;36mclean_andTokenize_text\u001b[0;34m(Text_file)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mSet_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_set_human_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# Tokenize Text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mText_tokenized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mText_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0;31m# Convert tokens to lowercase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mText_lowercase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mText_tokenized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserver_line\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \"\"\"\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m     return [token for sent in sentences\n\u001b[1;32m    132\u001b[0m             for token in _treebank_word_tokenizer.tokenize(sent)]\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \"\"\"\n\u001b[1;32m     96\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tokenizers/punkt/{0}.pickle'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;31m# Standard word tokenizer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1233\u001b[0m         \u001b[0mGiven\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m         \"\"\"\n\u001b[0;32m-> 1235\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentences_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdebug_decisions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36msentences_from_text\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1281\u001b[0m         \u001b[0mfollows\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mperiod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m         \"\"\"\n\u001b[0;32m-> 1283\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspan_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36mspan_tokenize\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1272\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1273\u001b[0m             \u001b[0mslices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_realign_boundaries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1274\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msentences_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1272\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1273\u001b[0m             \u001b[0mslices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_realign_boundaries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1274\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msentences_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_realign_boundaries\u001b[0;34m(self, text, slices)\u001b[0m\n\u001b[1;32m   1312\u001b[0m         \"\"\"\n\u001b[1;32m   1313\u001b[0m         \u001b[0mrealign\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1314\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msl1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_pair_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m             \u001b[0msl1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msl1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrealign\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msl2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_pair_iter\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    310\u001b[0m     \"\"\"\n\u001b[1;32m    311\u001b[0m     \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m     \u001b[0mprev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_slices_from_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m   1285\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m         \u001b[0mlast_break\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1287\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lang_vars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperiod_context_re\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinditer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1288\u001b[0m             \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_tok'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1289\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_contains_sentbreak\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "test_funct(df_docketsheet_master_file_preClass_timePeriods, Dict_key_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IMPORT ORIGINAL DOCKET SHEET FILE W/ PRE-CLASSIFIED ROWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adjust_rows_cols_docketsheet(df_docket_sheet):\n",
    "    \n",
    "    df_docketsheet_preclassified_narrow_col = df_docket_sheet.iloc[:,:7]\n",
    "    df_TP_int = df_docketsheet_preclassified_narrow_col['Time Period'] > 0\n",
    "    df_docketsheet_preclassified_narrow_TP = df_docketsheet_preclassified_narrow_col[df_TP_int]\n",
    "    \n",
    "    return df_docketsheet_preclassified_narrow_TP \n",
    "\n",
    "df_docketsheet_adj_rows_cols = adjust_rows_cols_docketsheet(df_docketsheet_master_file_preClass_timePeriods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stp1.get_docketsheet_ngrams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Notes:\n",
    "\n",
    "Input      =   Will now need to accept a Dict. \n",
    "\n",
    "Operations =   We will need to change the pipeline to clean the Docketsheet text based on the type of Ngrams. \n",
    "               a.) Idea:  if you check the first key of the dictionary and take the length, that will tell us\n",
    "                        what type of Ngram we are dealing with.\n",
    "                        Then you can run your cleaning module based on the type of Ngram. \n",
    "               b.) If our input variable is a Dictionary, then we will need to create an object that can\n",
    "                   hold each dataframe.  Probably a list would be most apt. \n",
    "               c.) Create an option to write the dataframes to Excel. \n",
    "               \n",
    "               Question:  Do we want to use the new technique to creating the key word appearance dataframe?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_freq_dist(Docketsheet, list_keywords):\n",
    "    '''The purpose of this function is to create a word frequency table for a set of documents for a set of key words\n",
    "    \n",
    "    Input  = Docketsheet: docket sheet entries + pre-classified life cycle stages \n",
    "             list_keywords = list of key words to match.  56 in total.  \n",
    "    \n",
    "    Operations:\n",
    "             1.) Create an empty dataframe whose index is the list of key words.  There are 56 in total. \n",
    "             2.) Create a count of the rows\n",
    "             3.) Iterate over the rows in the docket sheet dataframe as a list of tuples. \n",
    "             4.) Count the times the function iterates the row statement. \n",
    "             5.) Create a list to capture the matches for the 56 key-words for a single row. \n",
    "             6.) Important:  Because there are multiple rows for the same case, the number in the counter will need to be\n",
    "                 added to the column name else the columns will get over writen in the df_DAT[col] function. \n",
    "    \n",
    "    Output = 1.) A pandas dataframe whose rows constitute each row in the Docketsheet and whose columns are comprise of the \n",
    "             words in the key word list.  The data will be 1/0 depending on if the key words was a match or not. \n",
    "             2.) The final column of the dataframe will be the life cycle stage for each docket sheet entry. \n",
    "    '''\n",
    "    \n",
    "    # Create New Dataframe\n",
    "    df_DAT = pd.DataFrame({}, index = list_keywords)\n",
    "    \n",
    "    # Count of Rows\n",
    "    Count = 0\n",
    "\n",
    "    # Iterate over row of the docketsheet df as an enumerated tuple. \n",
    "    for row in Docketsheet.itertuples():\n",
    "\n",
    "        # Star the Count of the rows\n",
    "        Count += 1\n",
    "        \n",
    "        # List to capture each row.  List will reset on each iteration of the code. \n",
    "        List_word_matches_single_row = []\n",
    "        \n",
    "        # Clean row[4], which is the text column of the docketsheet. \n",
    "        clean_tokenize_row = s1_m.clean_andTokenize_text(row[4])                \n",
    "        \n",
    "        \n",
    "        # So iterate every word in key_word_list for each rows \n",
    "        for word in list_keywords:\n",
    "            \n",
    "            # Check to see if the word is in the clean text\n",
    "            if word in clean_tokenize_row:\n",
    "                # If there is a match, append 1 to the list\n",
    "                List_word_matches_single_row.append(1)\n",
    "            else: \n",
    "                # If not, append 0\n",
    "                List_word_matches_single_row.append(0)\n",
    "        \n",
    "        # Create a string from the counter to add to your column name. \n",
    "        Row_num = 'row' + str(Count) + ' ' \n",
    "        \n",
    "        # Create a column in your new datafrmae to capture the case number and list of matches. \n",
    "        df_DAT[Row_num + row[1] + ' ' + str(row[2])] = List_word_matches_single_row        \n",
    "\n",
    "        # Return our dataframe w/ an index as the list of key words, columns as each case. \n",
    "    \n",
    "    return df_DAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key_word_freq_docketsheet = get_freq_dist(df_docketsheet_adj_rows_cols, \n",
    "                                          Set_key_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row1 1:10-cv-00007-JEC 2010-01-04 00:00:00</th>\n",
       "      <th>row2 1:10-cv-00007-JEC 2010-03-16 00:00:00</th>\n",
       "      <th>row3 1:10-cv-00007-JEC 2010-04-15 00:00:00</th>\n",
       "      <th>row4 1:10-cv-00007-JEC 2010-04-19 00:00:00</th>\n",
       "      <th>row5 1:10-cv-00007-JEC 2010-11-12 00:00:00</th>\n",
       "      <th>row6 1:10-cv-00007-JEC 2010-11-29 00:00:00</th>\n",
       "      <th>row7 1:10-cv-00007-JEC 2011-01-20 00:00:00</th>\n",
       "      <th>row8 1:10-cv-00007-JEC 2011-01-26 00:00:00</th>\n",
       "      <th>row9 1:10-cv-00007-JEC 2011-03-18 00:00:00</th>\n",
       "      <th>row10 1:10-cv-00007-JEC 2011-04-01 00:00:00</th>\n",
       "      <th>...</th>\n",
       "      <th>row1286 1:16-cv-00305-MHC 2017-04-13 00:00:00</th>\n",
       "      <th>row1287 1:16-cv-00305-MHC 2017-04-18 00:00:00</th>\n",
       "      <th>row1288 1:16-cv-00305-MHC 2017-04-18 00:00:00</th>\n",
       "      <th>row1289 1:16-cv-00305-MHC 2017-08-31 00:00:00</th>\n",
       "      <th>row1290 1:16-cv-00305-MHC 2016-12-22 00:00:00</th>\n",
       "      <th>row1291 1:16-cv-00305-MHC 2017-01-24 00:00:00</th>\n",
       "      <th>row1292 1:16-cv-00305-MHC 2017-03-30 00:00:00</th>\n",
       "      <th>row1293 1:16-cv-00305-MHC 2017-03-30 00:00:00</th>\n",
       "      <th>row1294 1:16-cv-00305-MHC 2017-04-18 00:00:00</th>\n",
       "      <th>row1295 1:16-cv-00305-MHC 2017-05-02 00:00:00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pretrial</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clerk</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>includ</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>magistr</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fact</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1295 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          row1 1:10-cv-00007-JEC 2010-01-04 00:00:00  \\\n",
       "pretrial                                           1   \n",
       "clerk                                              0   \n",
       "includ                                             0   \n",
       "magistr                                            1   \n",
       "fact                                               0   \n",
       "\n",
       "          row2 1:10-cv-00007-JEC 2010-03-16 00:00:00  \\\n",
       "pretrial                                           1   \n",
       "clerk                                              0   \n",
       "includ                                             0   \n",
       "magistr                                            0   \n",
       "fact                                               0   \n",
       "\n",
       "          row3 1:10-cv-00007-JEC 2010-04-15 00:00:00  \\\n",
       "pretrial                                           0   \n",
       "clerk                                              0   \n",
       "includ                                             0   \n",
       "magistr                                            0   \n",
       "fact                                               0   \n",
       "\n",
       "          row4 1:10-cv-00007-JEC 2010-04-19 00:00:00  \\\n",
       "pretrial                                           0   \n",
       "clerk                                              0   \n",
       "includ                                             0   \n",
       "magistr                                            0   \n",
       "fact                                               0   \n",
       "\n",
       "          row5 1:10-cv-00007-JEC 2010-11-12 00:00:00  \\\n",
       "pretrial                                           0   \n",
       "clerk                                              0   \n",
       "includ                                             0   \n",
       "magistr                                            0   \n",
       "fact                                               0   \n",
       "\n",
       "          row6 1:10-cv-00007-JEC 2010-11-29 00:00:00  \\\n",
       "pretrial                                           0   \n",
       "clerk                                              0   \n",
       "includ                                             0   \n",
       "magistr                                            0   \n",
       "fact                                               0   \n",
       "\n",
       "          row7 1:10-cv-00007-JEC 2011-01-20 00:00:00  \\\n",
       "pretrial                                           0   \n",
       "clerk                                              0   \n",
       "includ                                             0   \n",
       "magistr                                            0   \n",
       "fact                                               1   \n",
       "\n",
       "          row8 1:10-cv-00007-JEC 2011-01-26 00:00:00  \\\n",
       "pretrial                                           0   \n",
       "clerk                                              1   \n",
       "includ                                             0   \n",
       "magistr                                            0   \n",
       "fact                                               0   \n",
       "\n",
       "          row9 1:10-cv-00007-JEC 2011-03-18 00:00:00  \\\n",
       "pretrial                                           0   \n",
       "clerk                                              0   \n",
       "includ                                             0   \n",
       "magistr                                            0   \n",
       "fact                                               0   \n",
       "\n",
       "          row10 1:10-cv-00007-JEC 2011-04-01 00:00:00  \\\n",
       "pretrial                                            0   \n",
       "clerk                                               0   \n",
       "includ                                              0   \n",
       "magistr                                             0   \n",
       "fact                                                0   \n",
       "\n",
       "                              ...                        \\\n",
       "pretrial                      ...                         \n",
       "clerk                         ...                         \n",
       "includ                        ...                         \n",
       "magistr                       ...                         \n",
       "fact                          ...                         \n",
       "\n",
       "          row1286 1:16-cv-00305-MHC 2017-04-13 00:00:00  \\\n",
       "pretrial                                              0   \n",
       "clerk                                                 0   \n",
       "includ                                                0   \n",
       "magistr                                               0   \n",
       "fact                                                  0   \n",
       "\n",
       "          row1287 1:16-cv-00305-MHC 2017-04-18 00:00:00  \\\n",
       "pretrial                                              0   \n",
       "clerk                                                 0   \n",
       "includ                                                0   \n",
       "magistr                                               0   \n",
       "fact                                                  0   \n",
       "\n",
       "          row1288 1:16-cv-00305-MHC 2017-04-18 00:00:00  \\\n",
       "pretrial                                              0   \n",
       "clerk                                                 1   \n",
       "includ                                                0   \n",
       "magistr                                               0   \n",
       "fact                                                  0   \n",
       "\n",
       "          row1289 1:16-cv-00305-MHC 2017-08-31 00:00:00  \\\n",
       "pretrial                                              0   \n",
       "clerk                                                 0   \n",
       "includ                                                0   \n",
       "magistr                                               0   \n",
       "fact                                                  0   \n",
       "\n",
       "          row1290 1:16-cv-00305-MHC 2016-12-22 00:00:00  \\\n",
       "pretrial                                              0   \n",
       "clerk                                                 1   \n",
       "includ                                                0   \n",
       "magistr                                               0   \n",
       "fact                                                  0   \n",
       "\n",
       "          row1291 1:16-cv-00305-MHC 2017-01-24 00:00:00  \\\n",
       "pretrial                                              0   \n",
       "clerk                                                 0   \n",
       "includ                                                0   \n",
       "magistr                                               0   \n",
       "fact                                                  0   \n",
       "\n",
       "          row1292 1:16-cv-00305-MHC 2017-03-30 00:00:00  \\\n",
       "pretrial                                              0   \n",
       "clerk                                                 1   \n",
       "includ                                                0   \n",
       "magistr                                               0   \n",
       "fact                                                  0   \n",
       "\n",
       "          row1293 1:16-cv-00305-MHC 2017-03-30 00:00:00  \\\n",
       "pretrial                                              0   \n",
       "clerk                                                 0   \n",
       "includ                                                0   \n",
       "magistr                                               0   \n",
       "fact                                                  0   \n",
       "\n",
       "          row1294 1:16-cv-00305-MHC 2017-04-18 00:00:00  \\\n",
       "pretrial                                              0   \n",
       "clerk                                                 0   \n",
       "includ                                                0   \n",
       "magistr                                               0   \n",
       "fact                                                  0   \n",
       "\n",
       "          row1295 1:16-cv-00305-MHC 2017-05-02 00:00:00  \n",
       "pretrial                                              0  \n",
       "clerk                                                 0  \n",
       "includ                                                0  \n",
       "magistr                                               0  \n",
       "fact                                                  0  \n",
       "\n",
       "[5 rows x 1295 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_word_freq_docketsheet.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transpose dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_final  = pd.DataFrame.transpose(key_word_freq_docketsheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pretrial</th>\n",
       "      <th>clerk</th>\n",
       "      <th>includ</th>\n",
       "      <th>magistr</th>\n",
       "      <th>fact</th>\n",
       "      <th>brief</th>\n",
       "      <th>materi</th>\n",
       "      <th>accordingli</th>\n",
       "      <th>report</th>\n",
       "      <th>settlement</th>\n",
       "      <th>...</th>\n",
       "      <th>approv</th>\n",
       "      <th>final</th>\n",
       "      <th>instruct</th>\n",
       "      <th>preliminari</th>\n",
       "      <th>certif</th>\n",
       "      <th>support</th>\n",
       "      <th>pursuant</th>\n",
       "      <th>appeal</th>\n",
       "      <th>stipul</th>\n",
       "      <th>joint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>row1 1:10-cv-00007-JEC 2010-01-04 00:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row2 1:10-cv-00007-JEC 2010-03-16 00:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            pretrial  clerk  includ  magistr  \\\n",
       "row1 1:10-cv-00007-JEC 2010-01-04 00:00:00         1      0       0        1   \n",
       "row2 1:10-cv-00007-JEC 2010-03-16 00:00:00         1      0       0        0   \n",
       "\n",
       "                                            fact  brief  materi  accordingli  \\\n",
       "row1 1:10-cv-00007-JEC 2010-01-04 00:00:00     0      0       0            0   \n",
       "row2 1:10-cv-00007-JEC 2010-03-16 00:00:00     0      0       0            0   \n",
       "\n",
       "                                            report  settlement  ...    approv  \\\n",
       "row1 1:10-cv-00007-JEC 2010-01-04 00:00:00       0           0  ...         0   \n",
       "row2 1:10-cv-00007-JEC 2010-03-16 00:00:00       0           0  ...         0   \n",
       "\n",
       "                                            final  instruct  preliminari  \\\n",
       "row1 1:10-cv-00007-JEC 2010-01-04 00:00:00      0         1            0   \n",
       "row2 1:10-cv-00007-JEC 2010-03-16 00:00:00      0         1            0   \n",
       "\n",
       "                                            certif  support  pursuant  appeal  \\\n",
       "row1 1:10-cv-00007-JEC 2010-01-04 00:00:00       0        0         0       0   \n",
       "row2 1:10-cv-00007-JEC 2010-03-16 00:00:00       0        0         0       0   \n",
       "\n",
       "                                            stipul  joint  \n",
       "row1 1:10-cv-00007-JEC 2010-01-04 00:00:00       0      0  \n",
       "row2 1:10-cv-00007-JEC 2010-03-16 00:00:00       0      0  \n",
       "\n",
       "[2 rows x 52 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Append Life Cycle Stage to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "List_Life_Cycles = [x for x in df_docketsheet_adj_rows_cols['Time Period']]\n",
    "\n",
    "df_final['Life Cycle Stage'] = List_Life_Cycles\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pretrial</th>\n",
       "      <th>clerk</th>\n",
       "      <th>includ</th>\n",
       "      <th>magistr</th>\n",
       "      <th>fact</th>\n",
       "      <th>brief</th>\n",
       "      <th>materi</th>\n",
       "      <th>accordingli</th>\n",
       "      <th>report</th>\n",
       "      <th>settlement</th>\n",
       "      <th>...</th>\n",
       "      <th>final</th>\n",
       "      <th>instruct</th>\n",
       "      <th>preliminari</th>\n",
       "      <th>certif</th>\n",
       "      <th>support</th>\n",
       "      <th>pursuant</th>\n",
       "      <th>appeal</th>\n",
       "      <th>stipul</th>\n",
       "      <th>joint</th>\n",
       "      <th>Life Cycle Stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>row1 1:10-cv-00007-JEC 2010-01-04 00:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row2 1:10-cv-00007-JEC 2010-03-16 00:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row3 1:10-cv-00007-JEC 2010-04-15 00:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row4 1:10-cv-00007-JEC 2010-04-19 00:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row5 1:10-cv-00007-JEC 2010-11-12 00:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row6 1:10-cv-00007-JEC 2010-11-29 00:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row7 1:10-cv-00007-JEC 2011-01-20 00:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row8 1:10-cv-00007-JEC 2011-01-26 00:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row9 1:10-cv-00007-JEC 2011-03-18 00:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row10 1:10-cv-00007-JEC 2011-04-01 00:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             pretrial  clerk  includ  magistr  \\\n",
       "row1 1:10-cv-00007-JEC 2010-01-04 00:00:00          1      0       0        1   \n",
       "row2 1:10-cv-00007-JEC 2010-03-16 00:00:00          1      0       0        0   \n",
       "row3 1:10-cv-00007-JEC 2010-04-15 00:00:00          0      0       0        0   \n",
       "row4 1:10-cv-00007-JEC 2010-04-19 00:00:00          0      0       0        0   \n",
       "row5 1:10-cv-00007-JEC 2010-11-12 00:00:00          0      0       0        0   \n",
       "row6 1:10-cv-00007-JEC 2010-11-29 00:00:00          0      0       0        0   \n",
       "row7 1:10-cv-00007-JEC 2011-01-20 00:00:00          0      0       0        0   \n",
       "row8 1:10-cv-00007-JEC 2011-01-26 00:00:00          0      1       0        0   \n",
       "row9 1:10-cv-00007-JEC 2011-03-18 00:00:00          0      0       0        0   \n",
       "row10 1:10-cv-00007-JEC 2011-04-01 00:00:00         0      0       0        0   \n",
       "\n",
       "                                             fact  brief  materi  accordingli  \\\n",
       "row1 1:10-cv-00007-JEC 2010-01-04 00:00:00      0      0       0            0   \n",
       "row2 1:10-cv-00007-JEC 2010-03-16 00:00:00      0      0       0            0   \n",
       "row3 1:10-cv-00007-JEC 2010-04-15 00:00:00      0      0       0            0   \n",
       "row4 1:10-cv-00007-JEC 2010-04-19 00:00:00      0      0       0            0   \n",
       "row5 1:10-cv-00007-JEC 2010-11-12 00:00:00      0      0       0            0   \n",
       "row6 1:10-cv-00007-JEC 2010-11-29 00:00:00      0      0       0            0   \n",
       "row7 1:10-cv-00007-JEC 2011-01-20 00:00:00      1      1       1            0   \n",
       "row8 1:10-cv-00007-JEC 2011-01-26 00:00:00      0      0       0            0   \n",
       "row9 1:10-cv-00007-JEC 2011-03-18 00:00:00      0      1       0            0   \n",
       "row10 1:10-cv-00007-JEC 2011-04-01 00:00:00     0      1       0            0   \n",
       "\n",
       "                                             report  settlement  \\\n",
       "row1 1:10-cv-00007-JEC 2010-01-04 00:00:00        0           0   \n",
       "row2 1:10-cv-00007-JEC 2010-03-16 00:00:00        0           0   \n",
       "row3 1:10-cv-00007-JEC 2010-04-15 00:00:00        0           0   \n",
       "row4 1:10-cv-00007-JEC 2010-04-19 00:00:00        1           0   \n",
       "row5 1:10-cv-00007-JEC 2010-11-12 00:00:00        0           1   \n",
       "row6 1:10-cv-00007-JEC 2010-11-29 00:00:00        0           0   \n",
       "row7 1:10-cv-00007-JEC 2011-01-20 00:00:00        0           0   \n",
       "row8 1:10-cv-00007-JEC 2011-01-26 00:00:00        0           0   \n",
       "row9 1:10-cv-00007-JEC 2011-03-18 00:00:00        0           0   \n",
       "row10 1:10-cv-00007-JEC 2011-04-01 00:00:00       0           0   \n",
       "\n",
       "                                                   ...         final  \\\n",
       "row1 1:10-cv-00007-JEC 2010-01-04 00:00:00         ...             0   \n",
       "row2 1:10-cv-00007-JEC 2010-03-16 00:00:00         ...             0   \n",
       "row3 1:10-cv-00007-JEC 2010-04-15 00:00:00         ...             0   \n",
       "row4 1:10-cv-00007-JEC 2010-04-19 00:00:00         ...             0   \n",
       "row5 1:10-cv-00007-JEC 2010-11-12 00:00:00         ...             0   \n",
       "row6 1:10-cv-00007-JEC 2010-11-29 00:00:00         ...             0   \n",
       "row7 1:10-cv-00007-JEC 2011-01-20 00:00:00         ...             0   \n",
       "row8 1:10-cv-00007-JEC 2011-01-26 00:00:00         ...             0   \n",
       "row9 1:10-cv-00007-JEC 2011-03-18 00:00:00         ...             0   \n",
       "row10 1:10-cv-00007-JEC 2011-04-01 00:00:00        ...             0   \n",
       "\n",
       "                                             instruct  preliminari  certif  \\\n",
       "row1 1:10-cv-00007-JEC 2010-01-04 00:00:00          1            0       0   \n",
       "row2 1:10-cv-00007-JEC 2010-03-16 00:00:00          1            0       0   \n",
       "row3 1:10-cv-00007-JEC 2010-04-15 00:00:00          0            0       0   \n",
       "row4 1:10-cv-00007-JEC 2010-04-19 00:00:00          0            1       0   \n",
       "row5 1:10-cv-00007-JEC 2010-11-12 00:00:00          0            0       0   \n",
       "row6 1:10-cv-00007-JEC 2010-11-29 00:00:00          0            0       0   \n",
       "row7 1:10-cv-00007-JEC 2011-01-20 00:00:00          0            0       0   \n",
       "row8 1:10-cv-00007-JEC 2011-01-26 00:00:00          0            0       0   \n",
       "row9 1:10-cv-00007-JEC 2011-03-18 00:00:00          0            0       0   \n",
       "row10 1:10-cv-00007-JEC 2011-04-01 00:00:00         0            0       0   \n",
       "\n",
       "                                             support  pursuant  appeal  \\\n",
       "row1 1:10-cv-00007-JEC 2010-01-04 00:00:00         0         0       0   \n",
       "row2 1:10-cv-00007-JEC 2010-03-16 00:00:00         0         0       0   \n",
       "row3 1:10-cv-00007-JEC 2010-04-15 00:00:00         0         0       0   \n",
       "row4 1:10-cv-00007-JEC 2010-04-19 00:00:00         0         0       0   \n",
       "row5 1:10-cv-00007-JEC 2010-11-12 00:00:00         0         0       0   \n",
       "row6 1:10-cv-00007-JEC 2010-11-29 00:00:00         0         0       0   \n",
       "row7 1:10-cv-00007-JEC 2011-01-20 00:00:00         1         0       0   \n",
       "row8 1:10-cv-00007-JEC 2011-01-26 00:00:00         0         0       0   \n",
       "row9 1:10-cv-00007-JEC 2011-03-18 00:00:00         0         0       0   \n",
       "row10 1:10-cv-00007-JEC 2011-04-01 00:00:00        0         0       0   \n",
       "\n",
       "                                             stipul  joint  Life Cycle Stage  \n",
       "row1 1:10-cv-00007-JEC 2010-01-04 00:00:00        0      0               1.0  \n",
       "row2 1:10-cv-00007-JEC 2010-03-16 00:00:00        0      0               2.0  \n",
       "row3 1:10-cv-00007-JEC 2010-04-15 00:00:00        0      0               5.0  \n",
       "row4 1:10-cv-00007-JEC 2010-04-19 00:00:00        0      0               5.0  \n",
       "row5 1:10-cv-00007-JEC 2010-11-12 00:00:00        0      0               2.0  \n",
       "row6 1:10-cv-00007-JEC 2010-11-29 00:00:00        0      0               5.0  \n",
       "row7 1:10-cv-00007-JEC 2011-01-20 00:00:00        0      0               6.0  \n",
       "row8 1:10-cv-00007-JEC 2011-01-26 00:00:00        0      0               6.0  \n",
       "row9 1:10-cv-00007-JEC 2011-03-18 00:00:00        0      0               6.0  \n",
       "row10 1:10-cv-00007-JEC 2011-04-01 00:00:00       0      0               6.0  \n",
       "\n",
       "[10 rows x 53 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\Chris.Cirelli\\Desktop\\Python Programming Docs\\GSU\\Sprint Project\\Docket-Sheet-Classification\\Result_Files_Key_Word_Attempt_2')\n",
    "s1_m.write_to_excel(df_final, 'Data Analytics Table_WordMatch_All_Docket_Entries_v6_03.11.2018')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_excel('Data Analytics Table_WordMatch_All_Docket_Entries_v6_03.11.2018.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pretrial</th>\n",
       "      <th>clerk</th>\n",
       "      <th>includ</th>\n",
       "      <th>magistr</th>\n",
       "      <th>fact</th>\n",
       "      <th>brief</th>\n",
       "      <th>materi</th>\n",
       "      <th>accordingli</th>\n",
       "      <th>report</th>\n",
       "      <th>settlement</th>\n",
       "      <th>...</th>\n",
       "      <th>final</th>\n",
       "      <th>instruct</th>\n",
       "      <th>preliminari</th>\n",
       "      <th>certif</th>\n",
       "      <th>support</th>\n",
       "      <th>pursuant</th>\n",
       "      <th>appeal</th>\n",
       "      <th>stipul</th>\n",
       "      <th>joint</th>\n",
       "      <th>Life Cycle Stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>row1 1:10-cv-00007-JEC 2010-01-04 00:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row2 1:10-cv-00007-JEC 2010-03-16 00:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row3 1:10-cv-00007-JEC 2010-04-15 00:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row4 1:10-cv-00007-JEC 2010-04-19 00:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row5 1:10-cv-00007-JEC 2010-11-12 00:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            pretrial  clerk  includ  magistr  \\\n",
       "row1 1:10-cv-00007-JEC 2010-01-04 00:00:00         1      0       0        1   \n",
       "row2 1:10-cv-00007-JEC 2010-03-16 00:00:00         1      0       0        0   \n",
       "row3 1:10-cv-00007-JEC 2010-04-15 00:00:00         0      0       0        0   \n",
       "row4 1:10-cv-00007-JEC 2010-04-19 00:00:00         0      0       0        0   \n",
       "row5 1:10-cv-00007-JEC 2010-11-12 00:00:00         0      0       0        0   \n",
       "\n",
       "                                            fact  brief  materi  accordingli  \\\n",
       "row1 1:10-cv-00007-JEC 2010-01-04 00:00:00     0      0       0            0   \n",
       "row2 1:10-cv-00007-JEC 2010-03-16 00:00:00     0      0       0            0   \n",
       "row3 1:10-cv-00007-JEC 2010-04-15 00:00:00     0      0       0            0   \n",
       "row4 1:10-cv-00007-JEC 2010-04-19 00:00:00     0      0       0            0   \n",
       "row5 1:10-cv-00007-JEC 2010-11-12 00:00:00     0      0       0            0   \n",
       "\n",
       "                                            report  settlement  \\\n",
       "row1 1:10-cv-00007-JEC 2010-01-04 00:00:00       0           0   \n",
       "row2 1:10-cv-00007-JEC 2010-03-16 00:00:00       0           0   \n",
       "row3 1:10-cv-00007-JEC 2010-04-15 00:00:00       0           0   \n",
       "row4 1:10-cv-00007-JEC 2010-04-19 00:00:00       1           0   \n",
       "row5 1:10-cv-00007-JEC 2010-11-12 00:00:00       0           1   \n",
       "\n",
       "                                                  ...         final  instruct  \\\n",
       "row1 1:10-cv-00007-JEC 2010-01-04 00:00:00        ...             0         1   \n",
       "row2 1:10-cv-00007-JEC 2010-03-16 00:00:00        ...             0         1   \n",
       "row3 1:10-cv-00007-JEC 2010-04-15 00:00:00        ...             0         0   \n",
       "row4 1:10-cv-00007-JEC 2010-04-19 00:00:00        ...             0         0   \n",
       "row5 1:10-cv-00007-JEC 2010-11-12 00:00:00        ...             0         0   \n",
       "\n",
       "                                            preliminari  certif  support  \\\n",
       "row1 1:10-cv-00007-JEC 2010-01-04 00:00:00            0       0        0   \n",
       "row2 1:10-cv-00007-JEC 2010-03-16 00:00:00            0       0        0   \n",
       "row3 1:10-cv-00007-JEC 2010-04-15 00:00:00            0       0        0   \n",
       "row4 1:10-cv-00007-JEC 2010-04-19 00:00:00            1       0        0   \n",
       "row5 1:10-cv-00007-JEC 2010-11-12 00:00:00            0       0        0   \n",
       "\n",
       "                                            pursuant  appeal  stipul  joint  \\\n",
       "row1 1:10-cv-00007-JEC 2010-01-04 00:00:00         0       0       0      0   \n",
       "row2 1:10-cv-00007-JEC 2010-03-16 00:00:00         0       0       0      0   \n",
       "row3 1:10-cv-00007-JEC 2010-04-15 00:00:00         0       0       0      0   \n",
       "row4 1:10-cv-00007-JEC 2010-04-19 00:00:00         0       0       0      0   \n",
       "row5 1:10-cv-00007-JEC 2010-11-12 00:00:00         0       0       0      0   \n",
       "\n",
       "                                            Life Cycle Stage  \n",
       "row1 1:10-cv-00007-JEC 2010-01-04 00:00:00                 1  \n",
       "row2 1:10-cv-00007-JEC 2010-03-16 00:00:00                 2  \n",
       "row3 1:10-cv-00007-JEC 2010-04-15 00:00:00                 5  \n",
       "row4 1:10-cv-00007-JEC 2010-04-19 00:00:00                 5  \n",
       "row5 1:10-cv-00007-JEC 2010-11-12 00:00:00                 2  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
