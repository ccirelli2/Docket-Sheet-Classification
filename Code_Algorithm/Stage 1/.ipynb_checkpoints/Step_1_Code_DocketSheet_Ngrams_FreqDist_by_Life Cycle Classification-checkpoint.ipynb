{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"DOCUMENTATION\\n\\nPurpose:        The purpose of the get_Ngram function is to obtain the Ngram frequency distribution for each of the predefined \\n                stages of the docketseet document. \\n           \\nUser Options    The user may chose from 4 types of Ngrams 'Nograms', 'Bigrams', 'Trigrams', and 'Quadgrams'. \\n                In addition, the user may chose to calculate the absolute frequency of the Ngram, which is the number of \\n                times that word appeared in the stage, or, the frequency of the Ngram divided by the number of rows in that\\n                stage, providing a calculation for how often on average the Ngram appears in each row of the stage. \\n\\nOutput:         A dataframe whos index is comprised of the Ngrams, columns the ll stages and content a combination of either\\n                of the two aforementioned user options. \\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''DOCUMENTATION\n",
    "\n",
    "Purpose:        The purpose of the get_Ngram function is to obtain the Ngram frequency distribution for each of the predefined \n",
    "                stages of the docketseet document. \n",
    "           \n",
    "User Options    The user may chose from 4 types of Ngrams 'Nograms', 'Bigrams', 'Trigrams', and 'Quadgrams'. \n",
    "                In addition, the user may chose to calculate the absolute frequency of the Ngram, which is the number of \n",
    "                times that word appeared in the stage, or, the frequency of the Ngram divided by the number of rows in that\n",
    "                stage, providing a calculation for how often on average the Ngram appears in each row of the stage. \n",
    "\n",
    "Output:         A dataframe whos index is comprised of the Ngrams, columns the ll stages and content a combination of either\n",
    "                of the two aforementioned user options. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT MODULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\\\Users\\\\Chris.Cirelli\\\\Desktop\\\\Python Programming Docs\\\\GSU\\\\Sprint Project\\\\Docket-Sheet-Classification\\\\Modules')\n",
    "import Step1_Module_Ngrams_FreqDist as stp1_Ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT DOCKET SHEET WITH PRE-CLASSIFIED TIME PERIODS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Docket_sheet_file = r'C:\\Users\\Chris.Cirelli\\Desktop\\Python Programming Docs\\GSU\\Sprint Project\\Docket-Sheet-Classification\\Data_Files_applicable_all_code\\DocketSheet Classification_70_02.22.2018.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Ngram_freq_dist_by_stage(Docket_sheet, Ngram_type = 'Nograms', Calculation_type = 'Frequency_distribution', \n",
    "                                To_excel = False, Location = None):\n",
    "    \n",
    "    ### Also, an option to chose whether you want an absolute freq or the % of the times the Ngram appears for a given stage. \n",
    "    \n",
    "    # Import the docketsheet as a dataframe and reshape. \n",
    "    df_Master_DocketSheet_File = stp1_Ngrams.import_docket_sheet_file(Docket_sheet)\n",
    "    \n",
    "    # Create a set object of the different time periods (stages) of the lawsuits. \n",
    "    Stages = set(df_Master_DocketSheet_File['Time Period'])\n",
    "    \n",
    "    # Create a Dataframe to house our Freq Dist \n",
    "    df_Freq_Dist = ''\n",
    "    \n",
    "    # Iterate over each stage in the Docket_sheet\n",
    "    for stage in Stages:\n",
    "        \n",
    "        # Print Progress\n",
    "        print('Creating the frequency distribution for stage =>', stage, '\\n')\n",
    "                \n",
    "        # Limit the DataFrame by each stage in succession so as to capture only those rows of the docketsheet tha \n",
    "        delimiter = df_Master_DocketSheet_File['Time Period'] == stage\n",
    "        df_limited = df_Master_DocketSheet_File[delimiter]\n",
    "        \n",
    "        # Dictonary to Capture Ngram Freq by Stage\n",
    "        Ngram_dictionary = {}\n",
    "        \n",
    "        # Count rows to serve as the denominator for our freq dist for each stage. \n",
    "        Count_rows = 0\n",
    "        \n",
    "        # Identify only the text of each row. \n",
    "        for row in df_limited.itertuples():\n",
    "            \n",
    "            # Count rows\n",
    "            Count_rows += 1\n",
    "            \n",
    "            # Get Text\n",
    "            text = row[4]\n",
    "            \n",
    "            # Clean & Tokenize the text\n",
    "            clean_tokenized_text = stp1_Ngrams.clean_andTokenize_text(text)\n",
    "            \n",
    "            # Get Ngrams\n",
    "            Ngrams = stp1_Ngrams.get_Ngrams(clean_tokenized_text, Ngram_type)\n",
    "            \n",
    "            # Loop over Ngrams\n",
    "            for ngram in Ngrams:\n",
    "                Ngram_dictionary[ngram] = Ngram_dictionary.get(ngram, 0) + 1\n",
    "        \n",
    "        # If we have not yet created the Stage 1 frequency distribution\n",
    "        if stage < 2:\n",
    "            # Create dataframe based on the calculation type chose. \n",
    "            if Calculation_type == 'Average_appearance':\n",
    "                df = pd.DataFrame(Ngram_dictionary, index = [stage]).transpose()\n",
    "                # If average appearance, devide the frequency by the count of rows for the stage in question. \n",
    "                df_avg_appearance = df / Count_rows\n",
    "                df_Freq_Dist = df_avg_appearance\n",
    "            \n",
    "            # If not 'Average appearance, simple use the frequency of the Ngram.  \n",
    "            else:\n",
    "                df_Freq_Dist = pd.DataFrame(Ngram_dictionary, index = [stage]).transpose()\n",
    "                \n",
    "        # If Stage 1 has already been created, then we will want to merge the remainder of the dataframes stages to df1.  \n",
    "        else:\n",
    "            if Calculation_type == 'Average_appearance':\n",
    "                df = pd.DataFrame(Ngram_dictionary, index = [stage]).transpose()\n",
    "                df_avg_appearance = df / Count_rows\n",
    "                df_Freq_Dist = df_Freq_Dist.merge(df_avg_appearance, how = 'outer', left_index = True, right_index = True)\n",
    "            else:\n",
    "                df = pd.DataFrame(Ngram_dictionary, index = [stage]).transpose()\n",
    "                df_Freq_Dist = df_Freq_Dist.merge(df, how = 'outer', left_index = True, right_index = True)\n",
    " \n",
    "    # Transform Dataframe - Create Ngram Column\n",
    "    \n",
    "    df_final = stp1_Ngrams.create_Ngram_column(df_Freq_Dist, Ngram_type)\n",
    "\n",
    "    # Write to Excel\n",
    "    if To_excel == True:\n",
    "        print('Writing dataframe to Excel')\n",
    "        os.chdir(Location)\n",
    "        File_name = str('Docketsheet_FreqDist' + '_' + Ngram_type + '_' + Calculation_type)\n",
    "        stp1_Ngrams.write_to_excel(df_final, Location, File_name)\n",
    "        print('Your file has been saved to:  ', Location)\n",
    "    # Once the list of ngrams is complete, return it to the user.\n",
    "    \n",
    "    return df_final\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Location = r'C:\\Users\\Chris.Cirelli\\Desktop\\Python Programming Docs\\GSU\\Sprint Project\\Docket-Sheet-Classification\\Result_Ngrams'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the frequency distribution for stage => 1.0 \n",
      "\n",
      "Creating the frequency distribution for stage => 2.0 \n",
      "\n",
      "Creating the frequency distribution for stage => 3.0 \n",
      "\n",
      "Creating the frequency distribution for stage => 4.0 \n",
      "\n",
      "Creating the frequency distribution for stage => 5.0 \n",
      "\n",
      "Creating the frequency distribution for stage => 6.0 \n",
      "\n",
      "Creating the frequency distribution for stage => 7.0 \n",
      "\n",
      "Creating the frequency distribution for stage => 8.0 \n",
      "\n",
      "Creating the frequency distribution for stage => 9.0 \n",
      "\n",
      "Creating the frequency distribution for stage => 10.0 \n",
      "\n",
      "Creating the frequency distribution for stage => 11.0 \n",
      "\n",
      "entered loop\n",
      "Writing dataframe to Excel\n",
      "Your file has been saved to:   C:\\Users\\Chris.Cirelli\\Desktop\\Python Programming Docs\\GSU\\Sprint Project\\Docket-Sheet-Classification\\Result_Ngrams\n"
     ]
    }
   ],
   "source": [
    "Ngram_freq_dist = get_Ngram_freq_dist_by_stage(Docket_sheet_file, 'Quadgrams', 'Average_appearance', True, Location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>6.0</th>\n",
       "      <th>7.0</th>\n",
       "      <th>8.0</th>\n",
       "      <th>9.0</th>\n",
       "      <th>10.0</th>\n",
       "      <th>11.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(abacu, corpor, attach, text)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001684</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(abacu, corpor, discoveri, end)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(abacu, corpor, first, interrogatori)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003367</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(abacu, corpor, lasai, brown)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001684</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(accord, frap, usca, mandat)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    0.0   1.0       2.0   3.0   4.0   \\\n",
       "0          (abacu, corpor, attach, text)   NaN       NaN   NaN   NaN   \n",
       "1        (abacu, corpor, discoveri, end)   NaN  0.008403   NaN   NaN   \n",
       "2  (abacu, corpor, first, interrogatori)   NaN       NaN   NaN   NaN   \n",
       "3          (abacu, corpor, lasai, brown)   NaN       NaN   NaN   NaN   \n",
       "4           (accord, frap, usca, mandat)   NaN       NaN   NaN   NaN   \n",
       "\n",
       "       5.0   6.0   7.0   8.0   9.0       10.0  11.0  \n",
       "0  0.001684   NaN   NaN   NaN   NaN       NaN   NaN  \n",
       "1       NaN   NaN   NaN   NaN   NaN       NaN   NaN  \n",
       "2  0.003367   NaN   NaN   NaN   NaN       NaN   NaN  \n",
       "3  0.001684   NaN   NaN   NaN   NaN       NaN   NaN  \n",
       "4       NaN   NaN   NaN   NaN   NaN  0.054054   NaN  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ngram_freq_dist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
