{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import graphviz\n",
    "from sklearn.tree import export_graphviz    \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "#   Classifiers\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'/home/ccirelli2/Desktop/Docket-Sheet-Classification/Modules')\n",
    "import Step4_Module_Machine_Learning_Algorithms as stp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Simple Decision Tree\n",
    "\n",
    "def simple_decision_tree(Features, Targets, Max_Depth , TrainTest = 'Train', Score = 'Precision'):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(Features, Targets)\n",
    "    clf = DecisionTreeClassifier(max_depth = Max_Depth, random_state = 50)\n",
    "    \n",
    "    # Fit Algorithm\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    #   Training Set\n",
    "    clf_pred = clf.predict(X_train)\n",
    "    report_train = sklearn.metrics.classification_report(y_train, clf_pred)\n",
    "    matrix_train = sklearn.metrics.confusion_matrix(y_train, clf_pred)\n",
    "    accuracy_train = sklearn.metrics.accuracy_score(y_train, clf_pred)\n",
    "    \n",
    "    # Test\n",
    "    clf_pred = clf.predict(X_test)\n",
    "    report_test = sklearn.metrics.classification_report(y_test, clf_pred)\n",
    "    matrix_test = sklearn.metrics.confusion_matrix(y_test, clf_pred)\n",
    "    accuracy_test = sklearn.metrics.accuracy_score(y_test, clf_pred)\n",
    "        \n",
    "  \n",
    "    # Print Results\n",
    "            \n",
    "    if Score == 'Accuracy':\n",
    "        if TrainTest == 'Train':\n",
    "            Accuracy_score = round(accuracy_train, 2)\n",
    "            return Accuracy_score\n",
    "        \n",
    "        elif TrainTest == 'Test':\n",
    "            Accuracy_score = round(accuracy_test, 2)\n",
    "            return Accuracy_score\n",
    "        \n",
    "    # Break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_predictions_decisionTree(Target_dir, Depth = 8, Ngram = 'Nograms', Write2Excel = False, Destination_location = None):\n",
    "    '''Documentation\n",
    "    \n",
    "    Input   = i.) Target_dir = location where our docketsheet key word frequencies are located. \n",
    "     \n",
    "    '''\n",
    "    # Dictionary to house values\n",
    "    Dict = {}\n",
    "    \n",
    "    # Change Directory\n",
    "    os.chdir(Target_dir)\n",
    "    \n",
    "    #Loop over files\n",
    "    for file in os.listdir():\n",
    "        \n",
    "        # If Ngram in file\n",
    "        if Ngram in file:\n",
    "            # Mark start of process\n",
    "            print('Generating prediction for =>', '\\n', file, '\\n')\n",
    "            # Get Features & Targets\n",
    "            Features = stp4.get_feature_target_dataframes(file, dataset = 'Features')\n",
    "            Targets  = stp4.get_feature_target_dataframes(file, dataset = 'Targets')\n",
    "            # Generate Prediction\n",
    "            Accuracy_train = simple_decision_tree(Features, Targets, \n",
    "                                                  Max_Depth = Depth, TrainTest = 'Train', \n",
    "                                                  Score = 'Accuracy')\n",
    "            \n",
    "            Accuracy_test = simple_decision_tree(Features, Targets, \n",
    "                                                  Max_Depth = Depth, TrainTest = 'Test', \n",
    "                                                  Score = 'Accuracy')\n",
    "            \n",
    "            # Create Dictionary\n",
    "            Dict[file] = (Accuracy_train, Accuracy_test)\n",
    "    \n",
    "    # Create Dataframe\n",
    "    df = pd.DataFrame(Dict)\n",
    "    df_transpose = df.transpose()\n",
    "    df_rename_cols = df_transpose.rename(index = str, columns = {0: 'Accuracy_train', \n",
    "                                                                 1: 'Accuracy_test'}) \n",
    "    df_final = df_rename_cols.sort_values(by = 'Accuracy_test', ascending = False)\n",
    "    \n",
    "    # Write to Excel\n",
    "    if Write2Excel == True:\n",
    "        print('Writing dataframe to Excel')\n",
    "        os.chdir(Destination_location)\n",
    "        File_name = 'Decision Tree Results for' + '_' + Ngram\n",
    "        print('File name => ' + File_name)\n",
    "        stp4.write_to_excel(df_final, Destination_location, File_name)\n",
    "        print('Your file has been saved to =>  ', Destination_location, '\\n', '\\n')\n",
    "        # Otherwise, return the dataframe to the user.    \n",
    "    else:\n",
    "        return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating prediction for => \n",
      " DocketSheet_WordMatches_TopWords_Nograms_CalculationII_AVG_not_zero_Top15_highest_STDV.xlsx.xlsx \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ccirelli2/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating prediction for => \n",
      " DocketSheet_WordMatches_TopWords_Nograms_CalculationII_AVG_not_zero_Top5_highest_STDV_AVG_below_20prct.xlsx.xlsx \n",
      "\n",
      "Generating prediction for => \n",
      " DocketSheet_WordMatches_TopWords_Nograms_CalculationIII_Correlation_Coefficient_Top15_highest_COCOEF.xlsx.xlsx \n",
      "\n",
      "Generating prediction for => \n",
      " DocketSheet_WordMatches_TopWords_Nograms_CalculationII_AVG_not_zero_Top5_lowest_STDV_highest_AVG.xlsx.xlsx \n",
      "\n",
      "Generating prediction for => \n",
      " DocketSheet_WordMatches_TopWords_Nograms_CalculationII_AVG_not_zero_Top5_highest_STDV_lowest_AVG.xlsx.xlsx \n",
      "\n",
      "Generating prediction for => \n",
      " DocketSheet_WordMatches_TopWords_Nograms_CalculationI_homebrew_STDV_Top5_highest_STDV_AVG_below_20prct.xlsx.xlsx \n",
      "\n",
      "Generating prediction for => \n",
      " DocketSheet_WordMatches_TopWords_Nograms_CalculationI_homebrew_STDV_Top5_highest_STDV_lowest_AVG.xlsx.xlsx \n",
      "\n",
      "Generating prediction for => \n",
      " DocketSheet_WordMatches_TopWords_Nograms_CalculationIII_Correlation_Coefficient_Top5_lowest_COCOEF_highest_AVG.xlsx.xlsx \n",
      "\n",
      "Generating prediction for => \n",
      " DocketSheet_WordMatches_TopWords_Nograms_CalculationI_homebrew_STDV_Top5_lowest_STDV_highest_AVG.xlsx.xlsx \n",
      "\n",
      "Writing dataframe to Excel\n",
      "File name => Decision Tree Results for_Nograms\n",
      "Your file has been saved to =>   /home/ccirelli2/Desktop/Docket-Sheet-Classification/Results_ML_Models \n",
      " \n",
      "\n",
      "Generating prediction for => \n",
      " DocketSheet_WordMatches_TopWords_Bigrams_CalculationII_AVG_not_zero_Top5_highest_STDV_lowest_AVG.xlsx.xlsx \n",
      "\n",
      "Generating prediction for => \n",
      " DocketSheet_WordMatches_TopWords_Bigrams_CalculationII_AVG_not_zero_Top5_highest_STDV_AVG_below_20prct.xlsx.xlsx \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ccirelli2/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating prediction for => \n",
      " DocketSheet_WordMatches_TopWords_Bigrams_CalculationII_AVG_not_zero_Top15_highest_STDV.xlsx.xlsx \n",
      "\n",
      "Generating prediction for => \n",
      " DocketSheet_WordMatches_TopWords_Bigrams_CalculationII_AVG_not_zero_Top5_lowest_STDV_highest_AVG.xlsx.xlsx \n",
      "\n",
      "Generating prediction for => \n",
      " DocketSheet_WordMatches_TopWords_Bigrams_CalculationI_homebrew_STDV_Top15_highest_STDV.xlsx.xlsx \n",
      "\n",
      "Generating prediction for => \n",
      " DocketSheet_WordMatches_TopWords_Bigrams_CalculationIII_Correlation_Coefficient_Top5_lowest_COCOEF_highest_AVG.xlsx.xlsx \n",
      "\n",
      "Generating prediction for => \n",
      " DocketSheet_WordMatches_TopWords_Bigrams_CalculationI_homebrew_STDV_Top5_highest_STDV_AVG_below_20prct.xlsx.xlsx \n",
      "\n",
      "Generating prediction for => \n",
      " DocketSheet_WordMatches_TopWords_Bigrams_CalculationI_homebrew_STDV_Top5_lowest_STDV_highest_AVG.xlsx.xlsx \n",
      "\n",
      "Writing dataframe to Excel\n",
      "File name => Decision Tree Results for_Bigrams\n",
      "Your file has been saved to =>   /home/ccirelli2/Desktop/Docket-Sheet-Classification/Results_ML_Models \n",
      " \n",
      "\n",
      "Generating prediction for => \n",
      " DocketSheet_WordMatches_TopWords_Trigrams_CalculationI_homebrew_STDV_Top5_highest_STDV_AVG_below_20prct.xlsx.xlsx \n",
      "\n",
      "Generating prediction for => \n",
      " DocketSheet_WordMatches_TopWords_Trigrams_CalculationI_homebrew_STDV_Top15_highest_STDV.xlsx.xlsx \n",
      "\n",
      "Generating prediction for => \n",
      " DocketSheet_WordMatches_TopWords_Trigrams_CalculationI_homebrew_STDV_Top5_lowest_STDV_highest_AVG.xlsx.xlsx \n",
      "\n",
      "Generating prediction for => \n",
      " DocketSheet_WordMatches_TopWords_Trigrams_CalculationII_AVG_not_zero_Top15_highest_STDV.xlsx.xlsx \n",
      "\n",
      "Generating prediction for => \n",
      " DocketSheet_WordMatches_TopWords_Trigrams_CalculationIII_Correlation_Coefficient_Top5_lowest_COCOEF_highest_AVG.xlsx.xlsx \n",
      "\n",
      "Generating prediction for => \n",
      " DocketSheet_WordMatches_TopWords_Trigrams_CalculationI_homebrew_STDV_Top5_highest_STDV_lowest_AVG.xlsx.xlsx \n",
      "\n",
      "Generating prediction for => \n",
      " DocketSheet_WordMatches_TopWords_Trigrams_CalculationII_AVG_not_zero_Top5_highest_STDV_AVG_below_20prct.xlsx.xlsx \n",
      "\n",
      "Writing dataframe to Excel\n",
      "File name => Decision Tree Results for_Trigrams\n",
      "Your file has been saved to =>   /home/ccirelli2/Desktop/Docket-Sheet-Classification/Results_ML_Models \n",
      " \n",
      "\n",
      "Generating prediction for => \n",
      " DocketSheet_WordMatches_TopWords_Quadgrams_CalculationIII_Correlation_Coefficient_Top15_highest_COCOEF.xlsx.xlsx \n",
      "\n",
      "Generating prediction for => \n",
      " DocketSheet_WordMatches_TopWords_Quadgrams_CalculationII_AVG_not_zero_Top5_highest_STDV_AVG_below_20prct.xlsx.xlsx \n",
      "\n",
      "Generating prediction for => \n",
      " DocketSheet_WordMatches_TopWords_Quadgrams_CalculationI_homebrew_STDV_Top5_highest_STDV_AVG_below_20prct.xlsx.xlsx \n",
      "\n",
      "Generating prediction for => \n",
      " DocketSheet_WordMatches_TopWords_Quadgrams_CalculationII_AVG_not_zero_Top5_lowest_STDV_highest_AVG.xlsx.xlsx \n",
      "\n",
      "Generating prediction for => \n",
      " DocketSheet_WordMatches_TopWords_Quadgrams_CalculationI_homebrew_STDV_Top15_highest_STDV.xlsx.xlsx \n",
      "\n",
      "Generating prediction for => \n",
      " DocketSheet_WordMatches_TopWords_Quadgrams_CalculationII_AVG_not_zero_Top5_highest_STDV_lowest_AVG.xlsx.xlsx \n",
      "\n",
      "Generating prediction for => \n",
      " DocketSheet_WordMatches_TopWords_Quadgrams_CalculationI_homebrew_STDV_Top5_highest_STDV_lowest_AVG.xlsx.xlsx \n",
      "\n",
      "Generating prediction for => \n",
      " DocketSheet_WordMatches_TopWords_Quadgrams_CalculationII_AVG_not_zero_Top15_highest_STDV.xlsx.xlsx \n",
      "\n",
      "Writing dataframe to Excel\n",
      "File name => Decision Tree Results for_Quadgrams\n",
      "Your file has been saved to =>   /home/ccirelli2/Desktop/Docket-Sheet-Classification/Results_ML_Models \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "Target_dir = r'/home/ccirelli2/Desktop/Docket-Sheet-Classification/Results_Docketsheet_wordMatches'\n",
    "Destination = r'/home/ccirelli2/Desktop/Docket-Sheet-Classification/Results_ML_Models'\n",
    "Ngram_options = ['Nograms', 'Bigrams', 'Trigrams', 'Quadgrams']\n",
    "\n",
    "for option in Ngram_options:\n",
    "    Prediction  = make_predictions_decisionTree(Target_dir, \n",
    "                                                Depth = 15, \n",
    "                                                Ngram = option, \n",
    "                                                Write2Excel = True, \n",
    "                                                Destination_location = Destination)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"OBSERVATIONS\\n\\nFeature_selection:      A depth of 30 appears to provide the best results. \\nPrecision & Recall:     The best so far as been .89 and .88. \\nStages:                 Stage 4 and 8 continue to perform the worst. \\nStage4:                 Incorrectly predicts stages 7 and 8.\\n                        Overlap:  only 1 word overlaps Stages 4 and 7 'Civil'. \\nStage8:                 Incorrectly predicts 4 and 5. \\n                        Overlap:  There is significant overlap between 8 and 4. Three words overlap in Word Group 2, which \\n                        is where the AVG is between 1-2% and CV is the highest. Two words overlap in Word Group 3, which \\n                        is our contrarian word group. \\n\\nOverall                 VAR is not a good measurement for identifying the top 5 words for our stage 1 and 2 as it removes\\n                        the sign from our frequencies such that a word with a large negative deviation could get put into\\n                        this group.  If we were only grabbing the top 15 words using VAT and or STDV we would probably be \\n                        ok.  \\n                        AVG of all other time periods runs into issues as many of the columns may have a 0% but others \\n                        could have a frequency at or higher than our target time period.  Therefore, we might think about\\n                        eliminating the columns with 0% when calculating our average.  This would force the code to \\n                        recognize a higher average for the other time periods. \\n\\nThoughts:               1.) Amend the Top5 selection code to calculate the AVG not using any of the Stages with 0%. \\n                        2.) Revert back to the old calculation which was ((Target/Avg)*Target) as it is sign sensitive    \\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''OBSERVATIONS\n",
    "\n",
    "Feature_selection:      A depth of 30 appears to provide the best results. \n",
    "Precision & Recall:     The best so far as been .89 and .88. \n",
    "Stages:                 Stage 4 and 8 continue to perform the worst. \n",
    "Stage4:                 Incorrectly predicts stages 7 and 8.\n",
    "                        Overlap:  only 1 word overlaps Stages 4 and 7 'Civil'. \n",
    "Stage8:                 Incorrectly predicts 4 and 5. \n",
    "                        Overlap:  There is significant overlap between 8 and 4. Three words overlap in Word Group 2, which \n",
    "                        is where the AVG is between 1-2% and CV is the highest. Two words overlap in Word Group 3, which \n",
    "                        is our contrarian word group. \n",
    "\n",
    "Overall                 VAR is not a good measurement for identifying the top 5 words for our stage 1 and 2 as it removes\n",
    "                        the sign from our frequencies such that a word with a large negative deviation could get put into\n",
    "                        this group.  If we were only grabbing the top 15 words using VAT and or STDV we would probably be \n",
    "                        ok.  \n",
    "                        AVG of all other time periods runs into issues as many of the columns may have a 0% but others \n",
    "                        could have a frequency at or higher than our target time period.  Therefore, we might think about\n",
    "                        eliminating the columns with 0% when calculating our average.  This would force the code to \n",
    "                        recognize a higher average for the other time periods. \n",
    "\n",
    "Thoughts:               1.) Amend the Top5 selection code to calculate the AVG not using any of the Stages with 0%. \n",
    "                        2.) Revert back to the old calculation which was ((Target/Avg)*Target) as it is sign sensitive    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
