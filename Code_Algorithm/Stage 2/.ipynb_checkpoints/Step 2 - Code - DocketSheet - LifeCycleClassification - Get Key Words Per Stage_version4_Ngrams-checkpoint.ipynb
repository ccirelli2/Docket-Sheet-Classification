{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT MODULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\Chris.Cirelli\\\\Desktop\\\\Python Programming Docs\\\\GSU\\\\Sprint Project\\\\Docket-Sheet-Classification\\\\Modules')\n",
    "\n",
    "import Step1_Module_Ngrams_FreqDist_version4_Ngrams as stp1\n",
    "# Module to Calculate Measurements of Central Tendancy\n",
    "import Step2_P1_Module_Calculations_Central_Tendancy-Copy_version4_Ngrams as stp2_cal_CT\n",
    "# Module to Calculate Top Words\n",
    "import Step2_P2_Module_Get_Top_Words as stp2_get_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT FREQUENCY DISTRIBUTION EXCEL FILE AS DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bigrams = pd.read_excel(r'C:\\Users\\Chris.Cirelli\\Desktop\\Python Programming Docs\\GSU\\Sprint Project\\Docket-Sheet-Classification\\Result_Ngrams\\Docketsheet_FreqDist_Bigrams_Average_appearance.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Trigrams = pd.read_excel(r'C:\\Users\\Chris.Cirelli\\Desktop\\Python Programming Docs\\GSU\\Sprint Project\\Docket-Sheet-Classification\\Result_Ngrams\\Docketsheet_FreqDist_Trigrams_Average_appearance.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>('abacu', 'corpor', 'attach', 'text')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001684</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>('abacu', 'corpor', 'discoveri', 'end')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>('abacu', 'corpor', 'first', 'interrogatori')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003367</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>('abacu', 'corpor', 'lasai', 'brown')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001684</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>('accord', 'frap', 'usca', 'mandat')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              0   1         2   3   4   \\\n",
       "0          ('abacu', 'corpor', 'attach', 'text') NaN       NaN NaN NaN   \n",
       "1        ('abacu', 'corpor', 'discoveri', 'end') NaN  0.008403 NaN NaN   \n",
       "2  ('abacu', 'corpor', 'first', 'interrogatori') NaN       NaN NaN NaN   \n",
       "3          ('abacu', 'corpor', 'lasai', 'brown') NaN       NaN NaN NaN   \n",
       "4           ('accord', 'frap', 'usca', 'mandat') NaN       NaN NaN NaN   \n",
       "\n",
       "         5   6   7   8   9         10  11  \n",
       "0  0.001684 NaN NaN NaN NaN       NaN NaN  \n",
       "1       NaN NaN NaN NaN NaN       NaN NaN  \n",
       "2  0.003367 NaN NaN NaN NaN       NaN NaN  \n",
       "3  0.001684 NaN NaN NaN NaN       NaN NaN  \n",
       "4       NaN NaN NaN NaN NaN  0.054054 NaN  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Quadgrams = pd.read_excel(r'C:\\Users\\Chris.Cirelli\\Desktop\\Python Programming Docs\\GSU\\Sprint Project\\Docket-Sheet-Classification\\Result_Ngrams\\Docketsheet_FreqDist_Quadgrams_Average_appearance.xlsx')\n",
    "Quadgrams.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas(Index=0, _1=\"('abacu', 'corpor', 'attach', 'text')\", _2=nan, _3=nan, _4=nan, _5=nan, _6=0.001683501683501683, _7=nan, _8=nan, _9=nan, _10=nan, _11=nan, _12=nan)\n",
      "Pandas(Index=1, _1=\"('abacu', 'corpor', 'discoveri', 'end')\", _2=nan, _3=0.0084033613445378148, _4=nan, _5=nan, _6=nan, _7=nan, _8=nan, _9=nan, _10=nan, _11=nan, _12=nan)\n",
      "Pandas(Index=2, _1=\"('abacu', 'corpor', 'first', 'interrogatori')\", _2=nan, _3=nan, _4=nan, _5=nan, _6=0.0033670033670033669, _7=nan, _8=nan, _9=nan, _10=nan, _11=nan, _12=nan)\n",
      "Pandas(Index=3, _1=\"('abacu', 'corpor', 'lasai', 'brown')\", _2=nan, _3=nan, _4=nan, _5=nan, _6=0.001683501683501683, _7=nan, _8=nan, _9=nan, _10=nan, _11=nan, _12=nan)\n",
      "Pandas(Index=4, _1=\"('accord', 'frap', 'usca', 'mandat')\", _2=nan, _3=nan, _4=nan, _5=nan, _6=nan, _7=nan, _8=nan, _9=nan, _10=nan, _11=0.054054054054054057, _12=nan)\n"
     ]
    }
   ],
   "source": [
    "for row in Quadgrams.head().itertuples():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"OBSERVATIONS\\n\\n1.) The index is no longer important, so any reference to the index will need to be moved to column 0. \\n2.) Column 0 did not exist in our old dataframes. So now we will need to adjust our code to exclude column 0 within the sort. \\n    So we will need to use a slicer everytime we rotate the dataframe to generate the calculations. \\n3.) We don't know yet whether or not we can match a tuple directly with the list of tokenized words, i.e. can you match \\n    a tuple with a list?\\n4.) We don't know if any of our threshholds make any sence, i.e. we haven't yet investigated the dataframes to see \\n    what is a relevant % of frequency / presence. \\n\\n\\n\\n\\n\\n\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''OBSERVATIONS\n",
    "\n",
    "1.) The index is no longer important, so any reference to the index will need to be moved to column 0. \n",
    "2.) Column 0 did not exist in our old dataframes. So now we will need to adjust our code to exclude column 0 within the sort. \n",
    "    So we will need to use a slicer everytime we rotate the dataframe to generate the calculations. \n",
    "3.) We don't know yet whether or not we can match a tuple directly with the list of tokenized words, i.e. can you match \n",
    "    a tuple with a list?\n",
    "4.) We don't know if any of our threshholds make any sence, i.e. we haven't yet investigated the dataframes to see \n",
    "    what is a relevant % of frequency / presence. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN FUNCTION TO GET TOP WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_words_toggle_methodology(dataframe_freq_distribution, methodology_CT, methodology_top_words):\n",
    "    '''\n",
    "    FUNCTION_I:     get_Measurements_CentralTendancy\n",
    "        Input       a.) The dataframe containing the word frequency distributions. b.) One of the below cal methodologies. sza\n",
    "        Options     'CalculationI_homebrew_STDV', \n",
    "                    'CalculationII_AVG_not_zero', \n",
    "                    'CalculationIII_Correlation_Coefficient'\n",
    "    \n",
    "    FUNCTION_II:    get_top_words\n",
    "        Input       a.) The dataframe containing the word frequency distribution, b.) One of the below methodologies, \n",
    "                    c.) The stage, which is defined within this namespace. \n",
    "        Options     'Top15_highest_STDV_homebrew', \n",
    "                    'Top15_highest_COCOEF', \n",
    "                    'Top5_highest_STDV_lowest_AVG', \n",
    "                    'Top5_highest_STDV_AVG_below_20prct', \n",
    "                    'Top5_lowest_STDV_highest_AVG', \n",
    "                    'Top5_lowest_COCOEF_highest_AVG'\n",
    "    \n",
    "    \n",
    "    '''\n",
    "\n",
    "    df_rename_cols = dataframe_freq_distribution                                    # removed the code to change the col\n",
    "                                                                                    # names to ints\n",
    "    \n",
    "    \n",
    "    # Create a new dataframe to capture the top words and set the index to 0-14\n",
    "    df_top_words = pd.DataFrame({}, index = [x for x in range(0,15)])\n",
    "    \n",
    "    # Reset df_rename_cols to just the columns 0-11\n",
    "    if len(df_rename_cols.columns) > 12:                                            # changed from 11 to 12\n",
    "        df_rename_cols = df_rename_cols.iloc[:, 0:11]\n",
    "        \n",
    "    # Keep Count of Life Cycle Stage\n",
    "    Stage = ''\n",
    "\n",
    "    # Iterative Function to Rotate Our Columns in Ascending Order. \n",
    "    for num in range(0,12):                                                         # Changed from 0,12 since we have a col 0 now\n",
    "        \n",
    "        # Loop Starts at Life Cycle 1.  Set Condition that when it reaches 11 it stops. \n",
    "        if df_rename_cols.columns[0] != 101:\n",
    "                       \n",
    "            # Stage\n",
    "            Stage = df_rename_cols.columns[0]\n",
    "            \n",
    "            # Calculate Measures of Central Tendancy\n",
    "            df_with_measures_of_CT = stp2_cal_CT.get_Measurements_CentralTendancy(df_rename_cols, methodology_CT)\n",
    "            \n",
    "            # Get Top Words\n",
    "            Top_words_all_calc = stp2_get_words.get_top_words(df_rename_cols, methodology_top_words, Stage)\n",
    "            \n",
    "            \n",
    "            # Define the column name\n",
    "            Col_name = str(Top_words_all_calc.columns[0])\n",
    "            \n",
    "            # Capture all rows and just the target column of the dataframe. \n",
    "            Top_words_target_stage = Top_words_all_calc.iloc[:,0]\n",
    "\n",
    "            # Append to our dataframe that will be returned to the user the top 5 words for each Life Cycle Stage.  \n",
    "            df_top_words[Col_name] = Top_words_target_stage\n",
    "            \n",
    "            # Reset df_rename_cols to just the columns 0-11\n",
    "            if len(df_rename_cols.columns) > 11:\n",
    "                df_rename_cols = df_rename_cols.iloc[:, 0:11]\n",
    "            \n",
    "            # Rename the first column to = num + 100.  Num = Original Col1 at each iteration.\n",
    "            df_col_increased_by100 = df_rename_cols.rename(index = str, columns = {num: num+100})\n",
    "            \n",
    "            # With the first column renamed, sort ascending.  This will move the first column to the end. \n",
    "            df_rotate = df_col_increased_by100.sort_index(axis = 1, ascending = True)\n",
    "            df_rename_cols = df_rotate\n",
    "    \n",
    "    return df_top_words\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          0   1         2   3         4         5   6   \\\n",
      "0        ('abacu', 'corpor') NaN  0.008403 NaN       NaN  0.015152 NaN   \n",
      "1         ('accord', 'frap') NaN       NaN NaN       NaN       NaN NaN   \n",
      "2  ('accordingli', 'action') NaN       NaN NaN  0.017241       NaN NaN   \n",
      "3  ('accordingli', 'adjust') NaN       NaN NaN       NaN  0.005051 NaN   \n",
      "4  ('accordingli', 'defend') NaN       NaN NaN       NaN       NaN NaN   \n",
      "\n",
      "         7   8   9         10  11  \n",
      "0       NaN NaN NaN       NaN NaN  \n",
      "1       NaN NaN NaN  0.054054 NaN  \n",
      "2       NaN NaN NaN       NaN NaN  \n",
      "3       NaN NaN NaN       NaN NaN  \n",
      "4  0.013514 NaN NaN       NaN NaN  \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ufunc 'subtract' did not contain a loop with signature matching types dtype('<U32') dtype('<U32') dtype('<U32')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-8ed24abe4179>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m df_with_measures_CT = get_top_words_toggle_methodology(Bigrams, \n\u001b[0;32m      2\u001b[0m                                                        \u001b[1;34m'CalculationIII_Correlation_Coefficient'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m                                                        'Top5_lowest_COCOEF_highest_AVG')\n\u001b[0m",
      "\u001b[1;32m<ipython-input-21-9b93dcfb5faa>\u001b[0m in \u001b[0;36mget_top_words_toggle_methodology\u001b[1;34m(dataframe_freq_distribution, methodology_CT, methodology_top_words)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[1;31m# Calculate Measures of Central Tendancy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m             \u001b[0mdf_with_measures_of_CT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstp2_cal_CT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_Measurements_CentralTendancy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_rename_cols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethodology_CT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[1;31m# Get Top Words\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Chris.Cirelli\\Desktop\\Python Programming Docs\\GSU\\Sprint Project\\Docket-Sheet-Classification\\Modules\\Step2_P1_Module_Calculations_Central_Tendancy.py\u001b[0m in \u001b[0;36mget_Measurements_CentralTendancy\u001b[1;34m(dataframe, measurement)\u001b[0m\n\u001b[0;32m    101\u001b[0m                 \u001b[0mAVG\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRow_not_equal_0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mCount_values_greater_zero\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m                 \u001b[1;31m# Calculate the Variance & the Standard deviation by the book.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m                 \u001b[0mVAR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mAVG\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m                 \u001b[0mSTDV\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVAR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m                 \u001b[1;31m# Calculate the Correlation Coefficient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: ufunc 'subtract' did not contain a loop with signature matching types dtype('<U32') dtype('<U32') dtype('<U32')"
     ]
    }
   ],
   "source": [
    "df_with_measures_CT = get_top_words_toggle_methodology(Bigrams, \n",
    "                                                       'CalculationIII_Correlation_Coefficient', \n",
    "                                                       'Top5_lowest_COCOEF_highest_AVG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITE RESULTS TO A SINGLE EXCEL SHEET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\Chris.Cirelli\\Desktop\\Python Programming Docs\\GSU\\Sprint Project\\Docket-Sheet-Classification\\Result_Files_Key_Word_Attempt_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stp1.write_to_excel(dataframe, 'name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ BACK IN THE FILE JUST CREATED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r'C:\\Users\\Chris.Cirelli\\Desktop\\Python Programming Docs\\GSU\\Sprint Project\\Docket-Sheet-Classification\\Result_Files_Key_Word_Attempt_2\\Top5_Key_words_03.11.2018_v3.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE A LIST OF A SINGLE SET OF THE KEY WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key_word_set(key_word_dataframe):\n",
    "    key_word_list = []\n",
    "    for x in key_word_dataframe:\n",
    "        word_list = list(key_word_dataframe[x])\n",
    "        [key_word_list.append(x) for x in word_list]\n",
    "    \n",
    "    key_word_set = list(set(key_word_list))\n",
    "    \n",
    "    df = pd.DataFrame(key_word_set)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_word_set = get_key_word_set(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1.write_to_excel(key_word_set, 'Key_word_set_4_algorithm_input_03.11.2018_v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
