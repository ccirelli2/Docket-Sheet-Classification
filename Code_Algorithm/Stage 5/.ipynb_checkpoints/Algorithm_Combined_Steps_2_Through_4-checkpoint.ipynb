{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IMPORT MODULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'/home/ccirelli2/Desktop/Docket-Sheet-Classification/Modules')\n",
    "import Step1_Module_Ngrams_FreqDist_version4_Ngrams as stp1\n",
    "import Step2_P2_Module_Get_Top_Words_version4_Ngrams as stp2\n",
    "import Step3_Module_Ngrams_Docketsheet_KeyWord_FreqDist as stp3\n",
    "import Step4_Module_Machine_Learning_Algorithms as stp4\n",
    "import Step4_Module_Measure_DocketSheetEntries_NoMatches as stp4_nomatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IMPORT FREQ DISTRIBUTION FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir(r'/home/ccirelli2/Desktop/Docket-Sheet-Classification/All_Results/Result_Ngrams')\n",
    "Nograms = pd.read_excel(r'Docketsheet_FreqDist_Nograms_Average_appearance.xlsx')\n",
    "Bigrams = pd.read_excel(r'Docketsheet_FreqDist_Bigrams_Average_appearance.xlsx')\n",
    "Trigrams = pd.read_excel(r'Docketsheet_FreqDist_Trigrams_Average_appearance.xlsx')\n",
    "Quadgrams = pd.read_excel(r'Docketsheet_FreqDist_Quadgrams_Average_appearance.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IMPORT DOCKETSHEET WITH PRE-CLASSIFIED STAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir(r'/home/ccirelli2/Desktop/Docket-Sheet-Classification/Data_Files_applicable_all_code')\n",
    "Docketsheet_master = 'DocketSheet Classification_70_02.22.2018.xlsx'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CREATE MASTER FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MasterFunction(stp2_FreqDist_file, \n",
    "                        stp2_Calculation_meth, stp2_methodology_top_words, \n",
    "                        stp2_write2excel, stp2_destination_location, \n",
    "                        stp2_Ngram_type,\n",
    "                   stp3_Docketsheet, \n",
    "                        stp3_DirNgramLoc, stp3_Iterable, \n",
    "                        stp3_KeyPhrase, stp3_Destination_location,\n",
    "                        stp3_Transpose4mlModel, stp3_Write2Excel,\n",
    "                   stp4_Target_dir, stp4_Depth, stp4_KeyWord, stp4_Write2Excel,\n",
    "                        stp4_Destination_location, stp4_Iterable, \n",
    "                        stp4_Metric):\n",
    "    '''DOCUMENTATION\n",
    "    \n",
    "    STEP2 - IDENTIFYING KEY NGRAMS\n",
    "    Inputs          i.) FreqDist_File - file where our frequency distributions are saved for each ngramtype.\n",
    "                    ii.) Calculation Method - see below; iii.) Methodology_top_words - see below; \n",
    "                    iv.) Write2excel  -self explanatory; v.) destination_location - where to write file; \n",
    "                    vi.) Ngramtype - tell algorithm which ngram type we are dealing with.  \n",
    "    Operations      (Basic Explanation) Based on the combinationof Calculation + Methodology, the algorithm\n",
    "                    will chose the KeyNgrams most unique (or least) to a given Stage. \n",
    "                    \n",
    "    Methodology Calculation of Central Tendencys\n",
    "                    Options     'CalculationI_homebrew_STDV', \n",
    "                                'CalculationII_AVG_not_zero', \n",
    "                                'CalculationIII_Correlation_Coefficient'\n",
    "    Methodology Top Words\n",
    "                    Options     'Top15_highest_STDV', \n",
    "                                'Top15_highest_COCOEF', \n",
    "                                'Top5_highest_STDV_lowest_AVG', \n",
    "                                'Top5_highest_STDV_AVG_below_20prct', \n",
    "                                'Top5_lowest_STDV_highest_AVG', \n",
    "                                'Top5_lowest_COCOEF_highest_AVG'\n",
    "    \n",
    "    STEP3 - GET KEY NGRAMS IN DOCKETSHEETS\n",
    "    Inputs         i.)   The original docketsheet with preclassified time periods (stages)\n",
    "                   ii.)  The KeyNgrams generated from Step2. \n",
    "    Output         iii.) A dataframe with the appearance of the KeyNgrams for each docket sheet entry. \n",
    "    \n",
    "    STEP4 - MACHINE LEARNING ALGORITHMS\n",
    "    Input:         i.)   Target_dir  = location where our docketsheet key word appearance dataframes are located. \n",
    "                   ii.)  Depth       = the depth that we want to use for our tree.  If not specified default \n",
    "                                     to 8. \n",
    "                   iii.) Write2Excel = if we want to write to Excel or work with the results in memory. \n",
    "                                     this feature is not yet set up for the confusion matrix or class report. \n",
    "                   iv.)  Destination = where we want to write our results to. \n",
    "                   v.)   Iterable    = whether we are working with a single or multiple files. \n",
    "                   vi.)  Single_file = if we chose False for the Iterable, then we will need to specify the \n",
    "                                     file we want to use. \n",
    "                vii.)    Metric      = the metric that we want to use to guage the performance of our model. \n",
    "                                     default to 'Accuracy'.  Can also chose 'Matrix' to return the confusion\n",
    "                                     matrix. \n",
    "                viii.)   KeyWord     = Choose the key word that you want to use to group the files (approachs)\n",
    "                                     to be used in the ML model. Examples include using the names of the \n",
    "                                     ngrmas ('Bigrams') or it could be STDV vs COCOEF, etc. \n",
    "    Operations i.)     The main operation here is either to iterate a list of files in a directory to \n",
    "                       generate the predictions or to work with one file.  That and the code is set up so \n",
    "                       that the user can have various choices as can be inferred from the input explanations. \n",
    "    \n",
    "    \n",
    "    '''   \n",
    "    # Step2: Get Key Ngrams From Frequency Distributions\n",
    "    TopWords_Toggle_Calc_Methodology           = stp2.get_top_words_toggle_methodology(\n",
    "                    # Features\n",
    "                    stp2_FreqDist_file         = stp2_FreqDist_file, \n",
    "                    stp2_Calculation_meth      = stp2_Calculation_meth, \n",
    "                    stp2_methodology_top_words = stp2_methodology_top_words, \n",
    "                    stp2_write2excel           = stp2_write2excel, \n",
    "                    stp2_destination_location  = stp2_destination_location, \n",
    "                    stp2_Ngram_type            = stp2_Ngram_type)\n",
    "    \n",
    "    # If writing to Excel, revert back to main dir where docketsheet is located. \n",
    "    os.chdir(r'/home/ccirelli2/Desktop/Docket-Sheet-Classification/Data_Files_applicable_all_code')\n",
    "    \n",
    "    # Step3: Get Key Ngram Appearance In Docketsheet Entries\n",
    "    KeyNgram_Appearance_DocketSheetEntries = stp3.get_DocketSheet_KeyWord_Appearance_Master(\n",
    "                    # Features\n",
    "                    stp3_Docketsheet           = stp3_Docketsheet, \n",
    "                    stp3_Target_file           = TopWords_Toggle_Calc_Methodology,\n",
    "                    stp3_DirNgramLoc           = stp3_DirNgramLoc, \n",
    "                    stp3_Iterable              = stp3_Iterable, \n",
    "                    stp3_KeyPhrase             = stp3_KeyPhrase, \n",
    "                    stp3_Destination_location  = stp3_Destination_location,\n",
    "                    stp3_Transpose4mlModel     = stp3_Transpose4mlModel, \n",
    "                    stp3_Write2Excel           = stp3_Write2Excel)\n",
    "    \n",
    "    \n",
    "    # Step4: Make Predictions Using the Machine Learning Algorithms\n",
    "    DecisionTreePrediction = stp4.make_predictions_decisionTree(\n",
    "                    stp4_Target_dir             = stp4_Target_dir,# Unless we plan to iterate a Dir, equals None.  \n",
    "                    stp4_Depth                  = stp4_Depth, \n",
    "                    stp4_KeyWord                = stp4_KeyWord, \n",
    "                    stp4_Write2Excel            = stp4_Write2Excel, \n",
    "                    stp4_Destination_location   = stp4_Destination_location, \n",
    "                    stp4_Iterable               = stp4_Iterable, \n",
    "                    stp4_Single_File            = KeyNgram_Appearance_DocketSheetEntries, \n",
    "                    stp4_Metric                 = stp4_Metric, \n",
    "                    df_inmemory_name            = stp2_Ngram_type + '_' + stp2_Calculation_meth + '_' + \n",
    "                                                    stp2_methodology_top_words + '_' + stp4_Metric + '_' +\n",
    "                                                     'Depth' + '_' + str(stp4_Depth))\n",
    "    \n",
    "    # Define In_memory_name\n",
    "    df_inmemory_name = str(stp2_Ngram_type + '_' + stp2_Calculation_meth + '_' + \n",
    "    stp2_methodology_top_words + '_' + stp4_Metric + '_' + 'Depth' + '_' + str(stp4_Depth))\n",
    "    \n",
    "    # Calculate the number of docket sheet rows without a match.  Send to user via print. \n",
    "    Count_zero = stp4_nomatch.get_count_nomatch_columns(\n",
    "        File = KeyNgram_Appearance_DocketSheetEntries, Count = 'Count_zero')\n",
    "    Count_total = stp4_nomatch.get_count_nomatch_columns(\n",
    "        File = KeyNgram_Appearance_DocketSheetEntries, Count = 'Count_all')\n",
    "    \n",
    "    \n",
    "    print('\\n', 'PREDICTION RESULTS:', '\\n')\n",
    "    print('The Ngram Key Selection resulted in =>' + ' ' + '%' + 'of overlap between the key words', '\\n')\n",
    "    print('This selection resulted in =>', '\\n', round(Count_zero/Count_total, 2)*100, ' ' + \n",
    "          'percentage of Docketsheet rows without a matching Ngram', '\\n')\n",
    "\n",
    "    return DecisionTreePrediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SUPPORTING OBJECTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Stp2_write_location = r'/home/ccirelli2/Desktop/Docket-Sheet-Classification/All_Results/Master_Code_Results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RUN FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating prediction for the dataframe passed from memory\n",
      "Accuracy train \n",
      " [[ 72   0   0   0   3   0   0   0   0   0   0]\n",
      " [  0  94   0   0   4   0   1   0   0   0   0]\n",
      " [  0   0  73   1   0   0   0   0   0   0   0]\n",
      " [  0   0   4  36   0   0   2   0   0   0   0]\n",
      " [  0   0   0   0 430   0   7   0   0   0   0]\n",
      " [  0   0   0   0   0  54   4   0   0   0   0]\n",
      " [  0   0   0   1   3   0  56   0   0   0   0]\n",
      " [  0   0   6   3   2   0   8  36   0   0   0]\n",
      " [  0   0   0   0   0   0   1   0   0   0   0]\n",
      " [  0   0   0   0   1   0   0   0   0  29   0]\n",
      " [  0   0   0   0   1   0   0   0   0   0  39]]\n",
      "Accuracy test \n",
      " [[ 21   2   1   0   1   0   0   0   0   0   0]\n",
      " [  3  27   0   0   2   0   1   0   0   0   0]\n",
      " [  0   1  15   4   0   0   0   6   0   0   0]\n",
      " [  0   0   1   6   0   0   3   4   0   0   0]\n",
      " [  0   1   0   1 137   1   0   0   0   0   0]\n",
      " [  0   0   0   0   3  14   0   0   0   0   0]\n",
      " [  0   0   0   1   4   0  10   1   0   0   0]\n",
      " [  0   0   4   3   4   0   2  16   0   1   0]\n",
      " [  0   0   0   0   2   0   0   0   0   0   0]\n",
      " [  0   0   1   0   0   0   0   0   0   4   0]\n",
      " [  0   0   0   0   1   0   0   0   0   0  15]]\n",
      "\n",
      " PREDICTION RESULTS: \n",
      "\n",
      "The Ngram Key Selection resulted in => %of overlap between the key words \n",
      "\n",
      "This selection resulted in => \n",
      " 0.0  percentage of Docketsheet rows without a matching Ngram \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ccirelli2/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "KeyNgrams = MasterFunction(\n",
    "                    stp2_FreqDist_file             = Nograms, \n",
    "                        stp2_Calculation_meth      = 'CalculationII_AVG_not_zero', \n",
    "                        stp2_methodology_top_words = 'Top15_highest_STDV', \n",
    "                        stp2_write2excel           = False, \n",
    "                        stp2_destination_location  = '/home/ccirelli2/Desktop/', \n",
    "                        stp2_Ngram_type            = 'Nograms', \n",
    "\n",
    "                    stp3_Docketsheet               = Docketsheet_master, \n",
    "                        stp3_DirNgramLoc           = None, \n",
    "                        stp3_Iterable              = False, \n",
    "                        stp3_KeyPhrase             = None, \n",
    "                        stp3_Destination_location  = None,\n",
    "                        stp3_Transpose4mlModel     = True, \n",
    "                        stp3_Write2Excel           = False,\n",
    "\n",
    "                     stp4_Target_dir               = '/home/ccirelli2/Desktop/',  \n",
    "                        stp4_Depth                 = 12, \n",
    "                        stp4_KeyWord               = None, # None as we are not looping over a Dir of files. \n",
    "                        stp4_Write2Excel           = False,\n",
    "                        stp4_Destination_location  = '/home/ccirelli2/Desktop/', \n",
    "                        stp4_Iterable              = False, \n",
    "                        stp4_Metric                = 'Matrix')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#stp3.write_to_excel(KeyNgrams, '/home/ccirelli2/Desktop/', 'OutputMasterFile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
