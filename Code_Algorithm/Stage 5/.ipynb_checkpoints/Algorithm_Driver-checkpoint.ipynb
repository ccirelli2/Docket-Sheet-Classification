{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IMPORT MODULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'/home/ccirelli2/Desktop/Docket-Sheet-Classification/Modules')\n",
    "import Step1_Module_Ngrams_FreqDist_version4_Ngrams as stp1\n",
    "import Step2_P2_Module_Get_Top_Words_version4_Ngrams as stp2\n",
    "import Step3_Module_Ngrams_Docketsheet_KeyWord_FreqDist as stp3\n",
    "import Step4_Module_Machine_Learning_Algorithms as stp4\n",
    "import Step5_Module_Measure_DocketSheetEntries_NoMatches as stp5_nomatch\n",
    "import Step5_Module_Measure_Dependencies_Between_Stages as stp5_dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IMPORT FREQ DISTRIBUTION FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir(r'/home/ccirelli2/Desktop/Docket-Sheet-Classification/All_Results/Result_Ngrams')\n",
    "Nograms = pd.read_excel(r'Docketsheet_FreqDist_Nograms_Average_appearance.xlsx')\n",
    "Bigrams = pd.read_excel(r'Docketsheet_FreqDist_Bigrams_Average_appearance.xlsx')\n",
    "Trigrams = pd.read_excel(r'Docketsheet_FreqDist_Trigrams_Average_appearance.xlsx')\n",
    "Quadgrams = pd.read_excel(r'Docketsheet_FreqDist_Quadgrams_Average_appearance.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IMPORT DOCKETSHEET WITH PRE-CLASSIFIED STAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir(r'/home/ccirelli2/Desktop/Docket-Sheet-Classification/Data_Files_applicable_all_code')\n",
    "Docketsheet_master = 'DocketSheet Classification_70_02.22.2018.xlsx'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CREATE MASTER FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MasterFunction(stp2_FreqDist_file, \n",
    "                        stp2_Calculation_meth, stp2_methodology_top_words, \n",
    "                        stp2_write2excel, stp2_destination_location, \n",
    "                        stp2_Ngram_type,\n",
    "                   stp3_Docketsheet, \n",
    "                        stp3_DirNgramLoc, stp3_Iterable, \n",
    "                        stp3_KeyPhrase, stp3_Destination_location,\n",
    "                        stp3_Transpose4mlModel, stp3_Write2Excel,\n",
    "                   stp4_Target_dir, stp4_Depth, stp4_KeyWord, stp4_Write2Excel,\n",
    "                        stp4_Destination_location, stp4_Iterable, \n",
    "                        stp4_Metric):\n",
    "    '''DOCUMENTATION\n",
    "    \n",
    "    STEP2 - IDENTIFYING KEY NGRAMS\n",
    "    Inputs          i.) FreqDist_File - file where our frequency distributions are saved for each ngramtype.\n",
    "                    ii.) Calculation Method - see below; iii.) Methodology_top_words - see below; \n",
    "                    iv.) Write2excel  -self explanatory; v.) destination_location - where to write file; \n",
    "                    vi.) Ngramtype - tell algorithm which ngram type we are dealing with.  \n",
    "    Operations      (Basic Explanation) Based on the combinationof Calculation + Methodology, the algorithm\n",
    "                    will chose the KeyNgrams most unique (or least) to a given Stage. \n",
    "                    \n",
    "    Methodology Calculation of Central Tendencys\n",
    "                    Options     'CalculationI_homebrew_STDV', \n",
    "                                'CalculationII_AVG_not_zero', \n",
    "                                'CalculationIII_Correlation_Coefficient'\n",
    "    Methodology Top Words\n",
    "                    Options     'Top15_highest_STDV', \n",
    "                                'Top15_highest_COCOEF', \n",
    "                                'Top5_highest_STDV_lowest_AVG', \n",
    "                                'Top5_highest_STDV_AVG_below_20prct', \n",
    "                                'Top5_lowest_STDV_highest_AVG', \n",
    "                                'Top5_lowest_COCOEF_highest_AVG'\n",
    "    \n",
    "    STEP3 - GET KEY NGRAMS IN DOCKETSHEETS\n",
    "    Inputs         i.)   The original docketsheet with preclassified time periods (stages)\n",
    "                   ii.)  The KeyNgrams generated from Step2. \n",
    "    Output         iii.) A dataframe with the appearance of the KeyNgrams for each docket sheet entry. \n",
    "    \n",
    "    STEP4 - MACHINE LEARNING ALGORITHMS\n",
    "    Input:         i.)   Target_dir  = location where our docketsheet key word appearance dataframes are located. \n",
    "                   ii.)  Depth       = the depth that we want to use for our tree.  If not specified default \n",
    "                                     to 8. \n",
    "                   iii.) Write2Excel = if we want to write to Excel or work with the results in memory. \n",
    "                                     this feature is not yet set up for the confusion matrix or class report. \n",
    "                   iv.)  Destination = where we want to write our results to. \n",
    "                   v.)   Iterable    = whether we are working with a single or multiple files. \n",
    "                   vi.)  Single_file = if we chose False for the Iterable, then we will need to specify the \n",
    "                                     file we want to use. \n",
    "                vii.)    Metric      = the metric that we want to use to guage the performance of our model. \n",
    "                                     default to 'Accuracy'.  Can also chose 'Matrix' to return the confusion\n",
    "                                     matrix, 'Report' to return  the classificaiton report, 'Export_Indv_Predictions' to \n",
    "                                     return a dataframe object containing the predictions.\n",
    "                viii.)   KeyWord     = Choose the key word that you want to use to group the files (approachs)\n",
    "                                     to be used in the ML model. Examples include using the names of the \n",
    "                                     ngrmas ('Bigrams') or it could be STDV vs COCOEF, etc. \n",
    "    Operations i.)     The main operation here is either to iterate a list of files in a directory to \n",
    "                       generate the predictions or to work with one file.  That and the code is set up so \n",
    "                       that the user can have various choices as can be inferred from the input explanations. \n",
    "    \n",
    "    \n",
    "    '''   \n",
    "    # Step2: Get Key Ngrams From Frequency Distributions\n",
    "    TopWords_Toggle_Calc_Methodology           = stp2.get_top_words_toggle_methodology(\n",
    "                    # Features\n",
    "                    stp2_FreqDist_file, \n",
    "                    stp2_Calculation_meth, \n",
    "                    stp2_methodology_top_words, \n",
    "                    stp2_write2excel, \n",
    "                    stp2_destination_location, \n",
    "                    stp2_Ngram_type)\n",
    "    \n",
    "    \n",
    "    # If writing to Excel, revert back to main dir where docketsheet is located. \n",
    "    os.chdir(r'/home/ccirelli2/Desktop/Docket-Sheet-Classification/Data_Files_applicable_all_code')\n",
    "     \n",
    "    # Step3: Get Key Ngram Appearance In Docketsheet Entries\n",
    "    KeyNgram_Appearance_DocketSheetEntries = stp3.get_DocketSheet_KeyWord_Appearance_Master(\n",
    "                    # Features\n",
    "                    stp3_Docketsheet                 = stp3_Docketsheet, \n",
    "                    stp3_DirNgramLoc                 = stp3_DirNgramLoc, \n",
    "                    stp3_Iterable                    = stp3_Iterable, \n",
    "                    stp3_KeyPhrase                   = stp3_KeyPhrase, \n",
    "                    stp3_Destination_location        = stp3_Destination_location,\n",
    "                    stp3_Transpose4mlModel           = stp3_Transpose4mlModel, \n",
    "                    stp3_Write2Excel                 = stp3_Write2Excel, \n",
    "                    stp3_Target_file                 = TopWords_Toggle_Calc_Methodology)\n",
    "    \n",
    "    \n",
    "    # Step4: Make Predictions Using the Machine Learning Algorithms\n",
    "    DecisionTreePrediction = stp4.make_predictions_decisionTree(\n",
    "                    stp4_Depth                       = stp4_Depth, \n",
    "                    stp4_KeyWord                     = stp4_KeyWord, \n",
    "                    stp4_Write2Excel                 = stp4_Write2Excel, \n",
    "                    stp4_Destination_location        = stp4_Destination_location, \n",
    "                    stp4_Iterable                    = stp4_Iterable, \n",
    "                    stp4_Metric                      = stp4_Metric,\n",
    "                    stp4_Target_dir             = stp4_Target_dir,# Unless we plan to iterate a Dir, equals None.  \n",
    "                    stp4_Single_File            = KeyNgram_Appearance_DocketSheetEntries,  \n",
    "                    df_inmemory_name            = stp2_Ngram_type + '_' + stp2_Calculation_meth + '_' + \n",
    "                                                    stp2_methodology_top_words + '_' + stp4_Metric + '_' +\n",
    "                                                     'Depth' + '_' + str(stp4_Depth))\n",
    "    \n",
    "    # Define In_memory_name\n",
    "    df_inmemory_name = str(stp2_Ngram_type + '_' + stp2_Calculation_meth + '_' + \n",
    "    stp2_methodology_top_words + '_' + stp4_Metric + '_' + 'Depth' + '_' + str(stp4_Depth))\n",
    "    \n",
    "    # Calculate the number of docket sheet rows without a match.  Send to user via print. \n",
    "    Count_zero = stp5_nomatch.get_count_nomatch_columns(\n",
    "        File = KeyNgram_Appearance_DocketSheetEntries, Count = 'Count_zero')\n",
    "    Count_total = stp5_nomatch.get_count_nomatch_columns(\n",
    "        File = KeyNgram_Appearance_DocketSheetEntries, Count = 'Count_all')\n",
    "    \n",
    "    # Calculate the extent of dependencies between the KeyWords in Each Stage. \n",
    "    Perct_dependency = stp5_dependencies.measure_dependencies(TopWords_Toggle_Calc_Methodology)\n",
    "    \n",
    "    # PRINT PREDICTION RESULTS\n",
    "    \n",
    "    print('\\n', 'PREDICTION RESULTS:', '\\n')\n",
    "    print('The Ngram Key Selection resulted in =>' + ' ' + str(Perct_dependency) + ' of overlap (dependency) between the key words', '\\n')\n",
    "    print('This selection resulted in =>', '\\n', round(Count_zero/Count_total, 2)*100, ' ' + \n",
    "          'percentage of Docketsheet rows without a matching Ngram', '\\n')\n",
    "\n",
    "    return DecisionTreePrediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NOTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNote that you the ytrain and test objects likely contain the arrays and attributes that we are calling like confusion matrix \\nand or report are likely just ways to arrange these predictions. \\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Note that you the ytrain and test objects likely contain the arrays and attributes that we are calling like confusion matrix \n",
    "and or report are likely just ways to arrange these predictions. \n",
    "\n",
    "\n",
    "**** Note that you created a new object in Step4, the decision tree model, that allows for you to return a dataframe of the \n",
    "individual predictions.  This function has dependencies, in particular the second function that generates the Accuracy, \n",
    "Matrics, etc scores.  You need to find a way to stop the second function from running and to only pass the data frame \n",
    "object to the user. \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RUN FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating prediction for the dataframe passed from memory\n",
      "##### y_test 130\n",
      "##### clf_pred 130\n",
      "##### y_test 130\n",
      "##### clf_pred 130\n",
      "Accuracy train \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.99      0.77      0.86        99\n",
      "        2.0       0.99      0.90      0.95       105\n",
      "        3.0       0.36      0.97      0.53        94\n",
      "        4.0       0.57      0.49      0.53        49\n",
      "        5.0       1.00      0.94      0.97       534\n",
      "        6.0       1.00      0.33      0.49        70\n",
      "        7.0       0.85      0.75      0.79        59\n",
      "        8.0       1.00      0.61      0.76        74\n",
      "        9.0       0.00      0.00      0.00         1\n",
      "       10.0       1.00      0.94      0.97        34\n",
      "       11.0       1.00      0.98      0.99        46\n",
      "\n",
      "avg / total       0.92      0.84      0.85      1165\n",
      "\n",
      "Accuracy test \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1.0       1.00      0.75      0.86        16\n",
      "        2.0       0.93      0.87      0.90        15\n",
      "        3.0       0.22      1.00      0.36         7\n",
      "        4.0       0.00      0.00      0.00         4\n",
      "        5.0       0.98      0.89      0.93        62\n",
      "        6.0       1.00      0.12      0.22         8\n",
      "        7.0       0.67      0.80      0.73         5\n",
      "        8.0       1.00      0.71      0.83         7\n",
      "       10.0       1.00      0.67      0.80         3\n",
      "       11.0       1.00      0.67      0.80         3\n",
      "\n",
      "avg / total       0.90      0.78      0.80       130\n",
      "\n",
      "\n",
      " PREDICTION RESULTS: \n",
      "\n",
      "The Ngram Key Selection resulted in => 10.0of overlap between the key words \n",
      "\n",
      "This selection resulted in => \n",
      " 3.0  percentage of Docketsheet rows without a matching Ngram \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ccirelli2/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "KeyNgrams = MasterFunction(\n",
    "                    stp2_FreqDist_file             = Nograms, \n",
    "                        stp2_Calculation_meth      = 'CalculationI_homebrew_STDV', \n",
    "                        stp2_methodology_top_words = 'Top5_highest_STDV_lowest_AVG', \n",
    "                        stp2_write2excel           = False, \n",
    "                        stp2_destination_location  = '/home/ccirelli2/Desktop/', \n",
    "                        stp2_Ngram_type            = 'Nograms', \n",
    "\n",
    "                    stp3_Docketsheet               = Docketsheet_master, \n",
    "                        stp3_DirNgramLoc           = None, \n",
    "                        stp3_Iterable              = False, \n",
    "                        stp3_KeyPhrase             = None, \n",
    "                        stp3_Destination_location  = None,\n",
    "                        stp3_Transpose4mlModel     = True, \n",
    "                        stp3_Write2Excel           = False, \n",
    "\n",
    "                     stp4_Target_dir               = '/home/ccirelli2/Desktop/',  \n",
    "                        stp4_Depth                 = 13,   # So far 12-13 has generated consistently the best results. \n",
    "                        stp4_KeyWord               = None, # None as we are not looping over a Dir of files. \n",
    "                        stp4_Write2Excel           = False,\n",
    "                        stp4_Destination_location  = '/home/ccirelli2/Desktop/', \n",
    "                        stp4_Iterable              = False, \n",
    "                        stp4_Metric                = 'Report')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#stp3.write_to_excel(KeyNgrams, '/home/ccirelli2/Desktop/', 'OutputMasterFile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy_train</th>\n",
       "      <th>Accuracy_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Nograms_CalculationI_homebrew_STDV_Top15_highest_STDV_Report_Depth_13</th>\n",
       "      <td>precision    recall  f1-score   s...</td>\n",
       "      <td>precision    recall  f1-score   s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                       Accuracy_train  \\\n",
       "Nograms_CalculationI_homebrew_STDV_Top15_highes...               precision    recall  f1-score   s...   \n",
       "\n",
       "                                                                                        Accuracy_test  \n",
       "Nograms_CalculationI_homebrew_STDV_Top15_highes...               precision    recall  f1-score   s...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KeyNgrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
