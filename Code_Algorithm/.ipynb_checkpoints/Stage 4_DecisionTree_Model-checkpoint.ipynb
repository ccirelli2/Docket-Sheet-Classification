{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import graphviz\n",
    "from sklearn.tree import export_graphviz    \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#   Classifiers\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\Chris.Cirelli\\\\Desktop\\\\Python Programming Docs\\\\GSU\\\\Sprint Project\\\\Docket-Sheet-Classification\\\\Modules')\n",
    "import Step1_Module as stp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\\\Users\\\\Chris.Cirelli\\\\Desktop\\\\Python Programming Docs\\\\GSU\\\\Sprint Project\\\\Docket-Sheet-Classification\\\\Result_Files_Key_Word_Attempt_2')\n",
    "\n",
    "df_DAT = pd.read_excel(r'C:\\Users\\Chris.Cirelli\\Desktop\\Python Programming Docs\\GSU\\Sprint Project\\Docket-Sheet-Classification\\Result_Files_Key_Word_Attempt_2\\Data Analytics Table_WordMatch_All_Docket_Entries_v2.xlsx')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Index (Docket Sheet Entries)\n",
    "\n",
    "df_reset_index = df_DAT.reset_index()\n",
    "df_drop_col1 = df_reset_index.drop('index', axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature = df_drop_col1.drop('Life Cycle Stage', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target = df_drop_col1['Life Cycle Stage']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Simple Decision Tree\n",
    "\n",
    "def simple_decision_tree(Features, Targets):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(Features, Targets, test_size=0.2)\n",
    "    clf = DecisionTreeClassifier(max_depth = 35, random_state = 50)\n",
    "    \n",
    "    # Fit Algorithm\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    #   Train\n",
    "    clf_pred = clf.predict(X_train)\n",
    "    report_train = sklearn.metrics.classification_report(y_train, clf_pred)\n",
    "    matrix_train = sklearn.metrics.confusion_matrix(y_train, clf_pred)\n",
    "    \n",
    "    #   Test\n",
    "    clf_pred = clf.predict(X_test)\n",
    "    report_test = sklearn.metrics.classification_report(y_test, clf_pred)\n",
    "    matrix_test = sklearn.metrics.confusion_matrix(y_test, clf_pred)\n",
    "    \n",
    "    print('Report Train', '\\n', report_train, '\\n')\n",
    "    print('Report Test', '\\n', report_test, '\\n')\n",
    "    print('Confusion Matrix Test', '\\n', matrix_test, '\\n')\n",
    "    \n",
    "    return matrix_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Tree Using GridSearchCV\n",
    "def tree_I_GridSearchCV(Features, Targets):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(Features, Targets, \n",
    "                                                        test_size=0.3, \n",
    "                                                        random_state = 50, \n",
    "                                                        stratify = Targets)\n",
    "    param_grid = {'max_depth': [20, 30, 40, 50], \n",
    "#                   'min_samples_split':[25,30,35], \n",
    "#                   'min_samples_leaf': [25,30,35], \n",
    "#                   'min_weight_fraction_leaf': [.01, .025, .05], \n",
    "#                   'max_features':[2,3,4], \n",
    "#                   'max_leaf_nodes':[15,20,25], \n",
    "                 }\n",
    "    tree = DecisionTreeClassifier()\n",
    "    grid_search = GridSearchCV(tree, param_grid, scoring = 'accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Train Prediction\n",
    "    prediction = grid_search.predict(X_train)\n",
    "    best_params = grid_search.best_params_\n",
    "    # Train Results\n",
    "    class_report = sklearn.metrics.classification_report(x_test, prediction)\n",
    "    print('Best Parameters =>', best_params, '\\n','\\n')\n",
    "    print('Train Classification Report: ', '\\n', class_report)\n",
    "    \n",
    "    # Test Prediction\n",
    "    prediction = grid_search.predict(ysqwas_test)\n",
    "    best_params = grid_search.best_params_\n",
    "    # Test Results\n",
    "    class_report = sklearn.metrics.classification_report(x_test, prediction)\n",
    "    print('Best Parameters =>', best_params, '\\n','\\n')\n",
    "    print('Train Classification Report: ', '\\n', class_report)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters => {'max_depth': 30} \n",
      " \n",
      "\n",
      "Train Classification Report:  \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      1.00      1.00        76\n",
      "          2       0.99      1.00      0.99        83\n",
      "          3       0.99      0.97      0.98        69\n",
      "          4       0.85      0.98      0.91        41\n",
      "          5       1.00      1.00      1.00       416\n",
      "          6       1.00      1.00      1.00        51\n",
      "          7       0.94      0.98      0.96        52\n",
      "          8       1.00      0.87      0.93        55\n",
      "          9       1.00      1.00      1.00         1\n",
      "         10       1.00      1.00      1.00        26\n",
      "         11       1.00      1.00      1.00        36\n",
      "\n",
      "avg / total       0.99      0.99      0.99       906\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris.Cirelli\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:581: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "Estimator not fitted, call `fit` before exploiting the model.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-92-4fa86b73cc06>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtree_I_GridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_feature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_target\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-91-459d430a473e>\u001b[0m in \u001b[0;36mtree_I_GridSearchCV\u001b[1;34m(Features, Targets)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Train Classification Report: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_report\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m     \u001b[0mclass_report\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_report\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Chris.Cirelli\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    402\u001b[0m         \"\"\"\n\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 404\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    405\u001b[0m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Chris.Cirelli\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    359\u001b[0m         \u001b[1;34m\"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 361\u001b[1;33m             raise NotFittedError(\"Estimator not fitted, \"\n\u001b[0m\u001b[0;32m    362\u001b[0m                                  \"call `fit` before exploiting the model.\")\n\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: Estimator not fitted, call `fit` before exploiting the model."
     ]
    }
   ],
   "source": [
    "tree_I_GridSearchCV(df_feature, df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Best Fit to Recall - Issue.  it is fitting recall very high for the non-claims, but still very low for teh actual claims.  See if you can run this for precision to get a better score. '"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#    Test GridSearchCV Tree on test subjects\n",
    "def tree_I_best_fit(Features, Targets):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(Features, Targets, test_size=0.3, random_state = 100, stratify = Targets)\n",
    "    tree = DecisionTreeClassifier(max_depth= 4, \n",
    "                                  max_features= 4, \n",
    "                                  max_leaf_nodes = 20, \n",
    "                                  min_samples_leaf= 25, \n",
    "                                  min_samples_split = 35, \n",
    "                                  min_weight_fraction_leaf = 0.01)\n",
    "    tree.fit(X_train, y_train)   \n",
    "    \n",
    "    #prediction_train = tree.predict(X_train)\n",
    "    #class_report_train = sklearn.metrics.classification_report(y_train, prediction_train)\n",
    "    #print(class_report_train)\n",
    "    prediction_test = tree.predict(X_test)\n",
    "    class_report_test = sklearn.metrics.classification_report(y_test, prediction_test)\n",
    "    print(class_report_test)\n",
    "\n",
    "'''Best Fit to Recall - Issue.  it is fitting recall very high for the non-claims, but still very low for teh actual claims.  See if you can run this for precision to get a better score. '''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.84      0.50      0.63        32\n",
      "          2       0.74      0.47      0.58        36\n",
      "          3       0.00      0.00      0.00        30\n",
      "          4       0.00      0.00      0.00        17\n",
      "          5       0.51      1.00      0.68       178\n",
      "          6       0.00      0.00      0.00        22\n",
      "          7       0.00      0.00      0.00        22\n",
      "          8       0.00      0.00      0.00        24\n",
      "          9       0.00      0.00      0.00         1\n",
      "         10       0.00      0.00      0.00        11\n",
      "         11       0.00      0.00      0.00        16\n",
      "\n",
      "avg / total       0.37      0.54      0.42       389\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris.Cirelli\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "tree_I_best_fit(df_feature, df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#   Original Random Tree\n",
    "def random_tree_I(Features, Targets):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(Features, Targets, test_size = 0.3, random_state = 50)\n",
    "    forest = RandomForestClassifier(n_estimators = 100, max_depth = 55, min_samples_split = 2, max_features = 4, min_samples_leaf = 1, min_impurity_split = .03)\n",
    "    forest.fit(X_train, y_train)\n",
    "    prediction_train = forest.predict(X_train)\n",
    "    recall_score_train = sklearn.metrics.classification_report(y_train, prediction_train)\n",
    "    prediction_test = forest.predict(X_test)\n",
    "    recall_score_test = sklearn.metrics.classification_report(y_test, prediction_test)\n",
    "    print('Recall score train => ', recall_score_train)\n",
    "    print('')\n",
    "    print('Recall score test => ', recall_score_test)\n",
    "        \n",
    "#   Best fit Random Tree\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall score train =>               precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      1.00      1.00        76\n",
      "          2       1.00      0.99      0.99        81\n",
      "          3       1.00      0.97      0.98        65\n",
      "          4       0.92      0.95      0.93        37\n",
      "          5       1.00      1.00      1.00       423\n",
      "          6       1.00      1.00      1.00        51\n",
      "          7       0.98      0.96      0.97        51\n",
      "          8       0.93      0.96      0.94        52\n",
      "          9       1.00      1.00      1.00         2\n",
      "         10       1.00      1.00      1.00        29\n",
      "         11       1.00      1.00      1.00        39\n",
      "\n",
      "avg / total       0.99      0.99      0.99       906\n",
      "\n",
      "\n",
      "Recall score test =>               precision    recall  f1-score   support\n",
      "\n",
      "          1       0.97      0.91      0.94        32\n",
      "          2       0.94      0.89      0.92        38\n",
      "          3       0.85      0.65      0.73        34\n",
      "          4       0.29      0.33      0.31        21\n",
      "          5       0.94      0.98      0.96       171\n",
      "          6       0.83      0.91      0.87        22\n",
      "          7       0.79      0.83      0.81        23\n",
      "          8       0.52      0.56      0.54        27\n",
      "         10       1.00      0.75      0.86         8\n",
      "         11       1.00      0.92      0.96        13\n",
      "\n",
      "avg / total       0.86      0.85      0.85       389\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_tree_I(df_feature, df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Example of Bagging\n",
    "    \n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "#from sklear.tree import DecisionTreeClassifier\n",
    "\n",
    "def decision_tree_baggin(Features, Targets):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(Features, Targets, test_size = 0.3)\n",
    "    bag_clf = BaggingClassifier(\n",
    "            n_estimators = 5,                      #train 500 different Decision Tree Classifiers. \n",
    "            max_samples = 200, \n",
    "            bootstrap = True, \n",
    "            n_jobs = -1)                            #number of classifiers to run at the same time.  If -1, then num jobs = num cores. \n",
    "\n",
    "    bag_clf.fit(X_train, y_train)\n",
    "    y_pred = bag_clf.predict(X_test)\n",
    "    score = sklearn.metrics.accuracy_score(y_test, y_pred)\n",
    "    print(score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bagger(Features, Targets):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(Features, Targets)\n",
    "    bg = BaggingClassifier(\n",
    "            RandomForestClassifier(),\n",
    "            max_samples = 2000, \n",
    "            max_features = 3, \n",
    "            n_estimators = 100)\n",
    "    bg.fit(X_train, y_train)\n",
    "    prediction = bg.predict(X_test)\n",
    "    score = sklearn.metrics.classification_report(y_test, prediction)\n",
    "    print(score)\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Booster(Features, Targets):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(Features, Targets)    \n",
    "    ada_clf = AdaBoostClassifier(\n",
    "            DecisionTreeClassifier(max_depth= 8, \n",
    "                                  max_features= 4, \n",
    "                                  max_leaf_nodes = 20, \n",
    "                                  min_samples_leaf= 25, \n",
    "                                  min_samples_split = 35, \n",
    "                                  min_weight_fraction_leaf = 0.01),\n",
    "            n_estimators = 200)\n",
    "    ada_clf.fit(X_train, y_train)\n",
    "    #prediction = ada_clf.predict((X_train))\n",
    "    #score = sklearn.metrics.classification_report(y_train, prediction)\n",
    "    prediction = ada_clf.predict((X_test))\n",
    "    score = sklearn.metrics.classification_report(y_test, prediction)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.40      0.79      0.53        28\n",
      "          2       0.64      0.29      0.40        31\n",
      "          3       0.54      0.54      0.54        26\n",
      "          4       0.33      0.33      0.33        12\n",
      "          5       0.84      0.78      0.81       150\n",
      "          6       0.71      0.56      0.63        18\n",
      "          7       0.17      0.26      0.20        19\n",
      "          8       0.19      0.18      0.18        17\n",
      "         10       1.00      0.44      0.62         9\n",
      "         11       1.00      1.00      1.00        14\n",
      "\n",
      "avg / total       0.67      0.62      0.63       324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Booster(df_feature, df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DecisionTreeRegressor_Boost(Features, Targets):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(Features, Targets)  \n",
    "    tree_reg1 = DecisionTreeRegressor()\n",
    "    tree_reg1.fit(X_train, y_train)   \n",
    "    prediction = tree_reg1.predict(X_train)\n",
    "    report = sklearn.metrics.classification_report(y_train, prediction)\n",
    "    return report\n",
    "     \n",
    "report = DecisionTreeRegressor(df_feature, df_target)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
